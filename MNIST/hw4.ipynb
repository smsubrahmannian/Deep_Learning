{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks for MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading MNIST\n",
    "Here we load the dataset and create data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ds = datasets.MNIST('../data', train=True, download=True, \n",
    "                       transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "test_ds = datasets.MNIST('../data', train=False, download=True, \n",
    "                       transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "#batch_size = 5 # for testing\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} \n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for the number of neurons in the hidden unit\n",
    "def get_model(M = 300):\n",
    "    net = nn.Sequential(nn.Linear(28*28, M),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(M, 10))\n",
    "    return net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(train_loader, test_loader, num_epochs, model, optimizer):\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):  \n",
    "            batch = images.shape[0] # size of the batch\n",
    "            # Convert torch tensor to Variable, change shape of the input\n",
    "            images = Variable(images.view(-1, 28*28)).cuda()\n",
    "            labels = Variable(labels).cuda()\n",
    "        \n",
    "            # Forward + Backward + Optimize\n",
    "            optimizer.zero_grad()  # zero the gradient buffer\n",
    "            outputs = model(images)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            total += batch\n",
    "            sum_loss += batch * loss.data[0]\n",
    "#             if (i+1) % 100 == 0:\n",
    "#                 print ('Epoch [%d/%d], Loss: %.4f' \n",
    "#                    %(epoch+1, num_epochs, sum_loss/total))\n",
    "                \n",
    "        train_loss = sum_loss/total\n",
    "        print('Epoch [%d/%d], Loss: %.4f' %(epoch+1, num_epochs, train_loss))\n",
    "        val_acc, val_loss = model_accuracy_loss(model, test_loader)\n",
    "        print('Epoch [%d/%d], Valid Accuracy: %.4f, Valid Loss: %.4f' %(epoch+1, num_epochs, val_acc, val_loss))\n",
    "    return val_acc, val_loss, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_accuracy_loss(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    sum_loss = 0.0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = Variable(images.view(-1, 28*28)).cuda()\n",
    "        labels = Variable(labels).cuda()\n",
    "        outputs = model(images)\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        sum_loss += labels.size(0)*loss.data[0]\n",
    "        total += labels.size(0)\n",
    "        correct += pred.eq(labels.data).cpu().sum()\n",
    "    return 100 * correct / total, sum_loss/ total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Question No 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 84.2484\n",
      "Epoch [1/10], Valid Accuracy: 13.7300, Valid Loss: 2.6949\n",
      "Epoch [2/10], Loss: 3.0887\n",
      "Epoch [2/10], Valid Accuracy: 11.7700, Valid Loss: 2.6268\n",
      "Epoch [3/10], Loss: 2.3953\n",
      "Epoch [3/10], Valid Accuracy: 11.1700, Valid Loss: 2.5699\n",
      "Epoch [4/10], Loss: 2.4004\n",
      "Epoch [4/10], Valid Accuracy: 10.4900, Valid Loss: 2.5607\n",
      "Epoch [5/10], Loss: 2.3695\n",
      "Epoch [5/10], Valid Accuracy: 10.0200, Valid Loss: 2.5570\n",
      "Epoch [6/10], Loss: 2.3643\n",
      "Epoch [6/10], Valid Accuracy: 10.0200, Valid Loss: 2.6581\n",
      "Epoch [7/10], Loss: 2.3640\n",
      "Epoch [7/10], Valid Accuracy: 11.5700, Valid Loss: 2.6079\n",
      "Epoch [8/10], Loss: 2.3649\n",
      "Epoch [8/10], Valid Accuracy: 9.7800, Valid Loss: 2.5598\n",
      "Epoch [9/10], Loss: 2.3664\n",
      "Epoch [9/10], Valid Accuracy: 9.7800, Valid Loss: 2.6625\n",
      "Epoch [10/10], Loss: 2.3634\n",
      "Epoch [10/10], Valid Accuracy: 10.3700, Valid Loss: 2.5903\n",
      "Epoch [1/10], Loss: 2.9661\n",
      "Epoch [1/10], Valid Accuracy: 38.4800, Valid Loss: 2.0190\n",
      "Epoch [2/10], Loss: 2.0799\n",
      "Epoch [2/10], Valid Accuracy: 16.5200, Valid Loss: 2.2051\n",
      "Epoch [3/10], Loss: 2.1058\n",
      "Epoch [3/10], Valid Accuracy: 17.3100, Valid Loss: 2.1434\n",
      "Epoch [4/10], Loss: 2.2612\n",
      "Epoch [4/10], Valid Accuracy: 11.9300, Valid Loss: 2.3029\n",
      "Epoch [5/10], Loss: 2.2590\n",
      "Epoch [5/10], Valid Accuracy: 13.0200, Valid Loss: 2.2654\n",
      "Epoch [6/10], Loss: 2.2654\n",
      "Epoch [6/10], Valid Accuracy: 10.7800, Valid Loss: 2.2888\n",
      "Epoch [7/10], Loss: 2.2749\n",
      "Epoch [7/10], Valid Accuracy: 12.3400, Valid Loss: 2.2418\n",
      "Epoch [8/10], Loss: 2.2720\n",
      "Epoch [8/10], Valid Accuracy: 14.5300, Valid Loss: 2.2402\n",
      "Epoch [9/10], Loss: 2.2082\n",
      "Epoch [9/10], Valid Accuracy: 16.9700, Valid Loss: 2.1724\n",
      "Epoch [10/10], Loss: 2.2279\n",
      "Epoch [10/10], Valid Accuracy: 11.7800, Valid Loss: 2.2958\n",
      "Epoch [1/10], Loss: 0.2826\n",
      "Epoch [1/10], Valid Accuracy: 94.1100, Valid Loss: 0.1957\n",
      "Epoch [2/10], Loss: 0.2031\n",
      "Epoch [2/10], Valid Accuracy: 94.4200, Valid Loss: 0.2206\n",
      "Epoch [3/10], Loss: 0.1842\n",
      "Epoch [3/10], Valid Accuracy: 94.9900, Valid Loss: 0.1958\n",
      "Epoch [4/10], Loss: 0.1826\n",
      "Epoch [4/10], Valid Accuracy: 94.7300, Valid Loss: 0.2298\n",
      "Epoch [5/10], Loss: 0.1705\n",
      "Epoch [5/10], Valid Accuracy: 94.1000, Valid Loss: 0.2692\n",
      "Epoch [6/10], Loss: 0.1599\n",
      "Epoch [6/10], Valid Accuracy: 95.6400, Valid Loss: 0.2141\n",
      "Epoch [7/10], Loss: 0.1632\n",
      "Epoch [7/10], Valid Accuracy: 95.7000, Valid Loss: 0.2136\n",
      "Epoch [8/10], Loss: 0.1549\n",
      "Epoch [8/10], Valid Accuracy: 94.8700, Valid Loss: 0.2408\n",
      "Epoch [9/10], Loss: 0.1571\n",
      "Epoch [9/10], Valid Accuracy: 94.7500, Valid Loss: 0.2612\n",
      "Epoch [10/10], Loss: 0.1462\n",
      "Epoch [10/10], Valid Accuracy: 95.2700, Valid Loss: 0.2591\n",
      "Epoch [1/10], Loss: 0.2235\n",
      "Epoch [1/10], Valid Accuracy: 96.7800, Valid Loss: 0.1044\n",
      "Epoch [2/10], Loss: 0.0902\n",
      "Epoch [2/10], Valid Accuracy: 97.0900, Valid Loss: 0.0965\n",
      "Epoch [3/10], Loss: 0.0622\n",
      "Epoch [3/10], Valid Accuracy: 97.6400, Valid Loss: 0.0787\n",
      "Epoch [4/10], Loss: 0.0463\n",
      "Epoch [4/10], Valid Accuracy: 97.6400, Valid Loss: 0.0732\n",
      "Epoch [5/10], Loss: 0.0357\n",
      "Epoch [5/10], Valid Accuracy: 97.9600, Valid Loss: 0.0674\n",
      "Epoch [6/10], Loss: 0.0275\n",
      "Epoch [6/10], Valid Accuracy: 98.1000, Valid Loss: 0.0704\n",
      "Epoch [7/10], Loss: 0.0220\n",
      "Epoch [7/10], Valid Accuracy: 97.6300, Valid Loss: 0.0845\n",
      "Epoch [8/10], Loss: 0.0217\n",
      "Epoch [8/10], Valid Accuracy: 97.8200, Valid Loss: 0.0796\n",
      "Epoch [9/10], Loss: 0.0172\n",
      "Epoch [9/10], Valid Accuracy: 98.1300, Valid Loss: 0.0796\n",
      "Epoch [10/10], Loss: 0.0149\n",
      "Epoch [10/10], Valid Accuracy: 97.5700, Valid Loss: 0.1042\n",
      "Epoch [1/10], Loss: 0.4851\n",
      "Epoch [1/10], Valid Accuracy: 92.8500, Valid Loss: 0.2608\n",
      "Epoch [2/10], Loss: 0.2340\n",
      "Epoch [2/10], Valid Accuracy: 94.3300, Valid Loss: 0.1941\n",
      "Epoch [3/10], Loss: 0.1808\n",
      "Epoch [3/10], Valid Accuracy: 95.3600, Valid Loss: 0.1613\n",
      "Epoch [4/10], Loss: 0.1463\n",
      "Epoch [4/10], Valid Accuracy: 95.9900, Valid Loss: 0.1379\n",
      "Epoch [5/10], Loss: 0.1224\n",
      "Epoch [5/10], Valid Accuracy: 96.5600, Valid Loss: 0.1167\n",
      "Epoch [6/10], Loss: 0.1044\n",
      "Epoch [6/10], Valid Accuracy: 96.9700, Valid Loss: 0.1034\n",
      "Epoch [7/10], Loss: 0.0909\n",
      "Epoch [7/10], Valid Accuracy: 97.2100, Valid Loss: 0.0956\n",
      "Epoch [8/10], Loss: 0.0791\n",
      "Epoch [8/10], Valid Accuracy: 97.3300, Valid Loss: 0.0918\n",
      "Epoch [9/10], Loss: 0.0699\n",
      "Epoch [9/10], Valid Accuracy: 97.5900, Valid Loss: 0.0855\n",
      "Epoch [10/10], Loss: 0.0621\n",
      "Epoch [10/10], Valid Accuracy: 97.6100, Valid Loss: 0.0793\n",
      "Epoch [1/10], Loss: 1.4005\n",
      "Epoch [1/10], Valid Accuracy: 84.7700, Valid Loss: 0.8065\n",
      "Epoch [2/10], Loss: 0.6412\n",
      "Epoch [2/10], Valid Accuracy: 88.3900, Valid Loss: 0.5055\n",
      "Epoch [3/10], Loss: 0.4659\n",
      "Epoch [3/10], Valid Accuracy: 89.5700, Valid Loss: 0.4065\n",
      "Epoch [4/10], Loss: 0.3940\n",
      "Epoch [4/10], Valid Accuracy: 90.6000, Valid Loss: 0.3566\n",
      "Epoch [5/10], Loss: 0.3537\n",
      "Epoch [5/10], Valid Accuracy: 91.1200, Valid Loss: 0.3261\n",
      "Epoch [6/10], Loss: 0.3268\n",
      "Epoch [6/10], Valid Accuracy: 91.6200, Valid Loss: 0.3048\n",
      "Epoch [7/10], Loss: 0.3072\n",
      "Epoch [7/10], Valid Accuracy: 91.9600, Valid Loss: 0.2892\n",
      "Epoch [8/10], Loss: 0.2915\n",
      "Epoch [8/10], Valid Accuracy: 92.2400, Valid Loss: 0.2766\n",
      "Epoch [9/10], Loss: 0.2782\n",
      "Epoch [9/10], Valid Accuracy: 92.5500, Valid Loss: 0.2648\n",
      "Epoch [10/10], Loss: 0.2669\n",
      "Epoch [10/10], Valid Accuracy: 92.7900, Valid Loss: 0.2559\n"
     ]
    }
   ],
   "source": [
    "valid_acc = []\n",
    "lr = [1, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "for l in lr:\n",
    "    net = get_model()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=l)\n",
    "    train_model(train_loader, test_loader, num_epochs=10, model=net, optimizer=optimizer)\n",
    "    vld_acc,_=model_accuracy_loss(net, test_loader)\n",
    "    valid_acc.append(vld_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa812249550>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQS9JFWfQS1LF/X86TitEw2FUgAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa812329e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lr,valid_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>vld_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>10.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.10000</td>\n",
       "      <td>11.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>92.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01000</td>\n",
       "      <td>95.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00100</td>\n",
       "      <td>97.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>97.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lr  vld_acc\n",
       "0  1.00000    10.37\n",
       "1  0.10000    11.78\n",
       "5  0.00001    92.79\n",
       "2  0.01000    95.27\n",
       "3  0.00100    97.57\n",
       "4  0.00010    97.61"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'lr':lr,\n",
    "             'vld_acc': valid_acc}).sort_values(by='vld_acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here, we have the highest validation accuracy of 97.61%, when the learning rate is 0.001. Any learning rate lower than that takes a lot more time to train and there is no visible increase in accuracy per epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The best value of learning rate is 0.0001 and the next best value is 0.001. Therefore we know that the best value of learning ratelines in between these two values. Therefore,I estimated the best learning rate by interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Learning rate after interpolation:  0.00055\n"
     ]
    }
   ],
   "source": [
    "print('Best Learning rate after interpolation: ',(0.0001+0.001)/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Question No 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.5037\n",
      "Epoch [1/10], Valid Accuracy: 88.8800, Valid Loss: 0.3981\n",
      "Epoch [2/10], Loss: 0.4112\n",
      "Epoch [2/10], Valid Accuracy: 89.7000, Valid Loss: 0.3681\n",
      "Epoch [3/10], Loss: 0.3834\n",
      "Epoch [3/10], Valid Accuracy: 89.7000, Valid Loss: 0.3725\n",
      "Epoch [4/10], Loss: 0.3799\n",
      "Epoch [4/10], Valid Accuracy: 90.0500, Valid Loss: 0.3729\n",
      "Epoch [5/10], Loss: 0.3756\n",
      "Epoch [5/10], Valid Accuracy: 89.3300, Valid Loss: 0.3806\n",
      "Epoch [6/10], Loss: 0.3669\n",
      "Epoch [6/10], Valid Accuracy: 90.1900, Valid Loss: 0.3602\n",
      "Epoch [7/10], Loss: 0.3658\n",
      "Epoch [7/10], Valid Accuracy: 89.5700, Valid Loss: 0.3676\n",
      "Epoch [8/10], Loss: 0.3631\n",
      "Epoch [8/10], Valid Accuracy: 89.7000, Valid Loss: 0.3740\n",
      "Epoch [9/10], Loss: 0.3588\n",
      "Epoch [9/10], Valid Accuracy: 90.2600, Valid Loss: 0.3615\n",
      "Epoch [10/10], Loss: 0.3573\n",
      "Epoch [10/10], Valid Accuracy: 89.1200, Valid Loss: 0.3930\n",
      "Epoch [1/10], Loss: 0.2734\n",
      "Epoch [1/10], Valid Accuracy: 94.2400, Valid Loss: 0.1928\n",
      "Epoch [2/10], Loss: 0.1970\n",
      "Epoch [2/10], Valid Accuracy: 94.7500, Valid Loss: 0.1824\n",
      "Epoch [3/10], Loss: 0.1786\n",
      "Epoch [3/10], Valid Accuracy: 94.2900, Valid Loss: 0.2071\n",
      "Epoch [4/10], Loss: 0.1733\n",
      "Epoch [4/10], Valid Accuracy: 94.9900, Valid Loss: 0.1960\n",
      "Epoch [5/10], Loss: 0.1716\n",
      "Epoch [5/10], Valid Accuracy: 94.7300, Valid Loss: 0.2128\n",
      "Epoch [6/10], Loss: 0.1642\n",
      "Epoch [6/10], Valid Accuracy: 95.4600, Valid Loss: 0.2053\n",
      "Epoch [7/10], Loss: 0.1689\n",
      "Epoch [7/10], Valid Accuracy: 94.6000, Valid Loss: 0.2339\n",
      "Epoch [8/10], Loss: 0.1690\n",
      "Epoch [8/10], Valid Accuracy: 95.1800, Valid Loss: 0.2315\n",
      "Epoch [9/10], Loss: 0.1541\n",
      "Epoch [9/10], Valid Accuracy: 94.8200, Valid Loss: 0.2473\n",
      "Epoch [10/10], Loss: 0.1542\n",
      "Epoch [10/10], Valid Accuracy: 95.2100, Valid Loss: 0.2571\n",
      "Epoch [1/10], Loss: 0.2732\n",
      "Epoch [1/10], Valid Accuracy: 94.3400, Valid Loss: 0.2125\n",
      "Epoch [2/10], Loss: 0.2056\n",
      "Epoch [2/10], Valid Accuracy: 94.1100, Valid Loss: 0.2319\n",
      "Epoch [3/10], Loss: 0.1836\n",
      "Epoch [3/10], Valid Accuracy: 94.8500, Valid Loss: 0.1995\n",
      "Epoch [4/10], Loss: 0.1747\n",
      "Epoch [4/10], Valid Accuracy: 95.0100, Valid Loss: 0.2162\n",
      "Epoch [5/10], Loss: 0.1733\n",
      "Epoch [5/10], Valid Accuracy: 94.8900, Valid Loss: 0.2349\n",
      "Epoch [6/10], Loss: 0.1647\n",
      "Epoch [6/10], Valid Accuracy: 95.6600, Valid Loss: 0.2052\n",
      "Epoch [7/10], Loss: 0.1588\n",
      "Epoch [7/10], Valid Accuracy: 95.3500, Valid Loss: 0.2317\n",
      "Epoch [8/10], Loss: 0.1534\n",
      "Epoch [8/10], Valid Accuracy: 95.3600, Valid Loss: 0.2143\n",
      "Epoch [9/10], Loss: 0.1621\n",
      "Epoch [9/10], Valid Accuracy: 95.5400, Valid Loss: 0.2426\n",
      "Epoch [10/10], Loss: 0.1478\n",
      "Epoch [10/10], Valid Accuracy: 95.1000, Valid Loss: 0.2506\n",
      "Epoch [1/10], Loss: 0.2869\n",
      "Epoch [1/10], Valid Accuracy: 94.3200, Valid Loss: 0.2189\n",
      "Epoch [2/10], Loss: 0.2030\n",
      "Epoch [2/10], Valid Accuracy: 95.2900, Valid Loss: 0.2012\n",
      "Epoch [3/10], Loss: 0.2006\n",
      "Epoch [3/10], Valid Accuracy: 93.6000, Valid Loss: 0.2598\n",
      "Epoch [4/10], Loss: 0.1825\n",
      "Epoch [4/10], Valid Accuracy: 95.1400, Valid Loss: 0.2109\n",
      "Epoch [5/10], Loss: 0.1749\n",
      "Epoch [5/10], Valid Accuracy: 94.3600, Valid Loss: 0.2563\n",
      "Epoch [6/10], Loss: 0.1706\n",
      "Epoch [6/10], Valid Accuracy: 94.8800, Valid Loss: 0.2346\n",
      "Epoch [7/10], Loss: 0.1624\n",
      "Epoch [7/10], Valid Accuracy: 93.9800, Valid Loss: 0.3256\n",
      "Epoch [8/10], Loss: 0.1582\n",
      "Epoch [8/10], Valid Accuracy: 95.5600, Valid Loss: 0.2608\n",
      "Epoch [9/10], Loss: 0.1651\n",
      "Epoch [9/10], Valid Accuracy: 94.9500, Valid Loss: 0.3016\n",
      "Epoch [10/10], Loss: 0.1609\n",
      "Epoch [10/10], Valid Accuracy: 95.4500, Valid Loss: 0.2696\n",
      "Epoch [1/10], Loss: 0.3166\n",
      "Epoch [1/10], Valid Accuracy: 94.7800, Valid Loss: 0.1900\n",
      "Epoch [2/10], Loss: 0.2275\n",
      "Epoch [2/10], Valid Accuracy: 93.8500, Valid Loss: 0.2464\n",
      "Epoch [3/10], Loss: 0.1977\n",
      "Epoch [3/10], Valid Accuracy: 95.4000, Valid Loss: 0.2076\n",
      "Epoch [4/10], Loss: 0.1833\n",
      "Epoch [4/10], Valid Accuracy: 95.1000, Valid Loss: 0.2119\n",
      "Epoch [5/10], Loss: 0.1801\n",
      "Epoch [5/10], Valid Accuracy: 93.9800, Valid Loss: 0.2970\n",
      "Epoch [6/10], Loss: 0.1717\n",
      "Epoch [6/10], Valid Accuracy: 95.2100, Valid Loss: 0.2467\n",
      "Epoch [7/10], Loss: 0.1622\n",
      "Epoch [7/10], Valid Accuracy: 95.2700, Valid Loss: 0.2485\n",
      "Epoch [8/10], Loss: 0.1631\n",
      "Epoch [8/10], Valid Accuracy: 95.1800, Valid Loss: 0.2638\n",
      "Epoch [9/10], Loss: 0.1508\n",
      "Epoch [9/10], Valid Accuracy: 95.0400, Valid Loss: 0.2860\n",
      "Epoch [10/10], Loss: 0.1614\n",
      "Epoch [10/10], Valid Accuracy: 94.8200, Valid Loss: 0.3221\n",
      "Epoch [1/10], Loss: 0.3570\n",
      "Epoch [1/10], Valid Accuracy: 94.8900, Valid Loss: 0.2156\n",
      "Epoch [2/10], Loss: 0.2188\n",
      "Epoch [2/10], Valid Accuracy: 94.7100, Valid Loss: 0.2131\n",
      "Epoch [3/10], Loss: 0.2049\n",
      "Epoch [3/10], Valid Accuracy: 94.2800, Valid Loss: 0.2397\n",
      "Epoch [4/10], Loss: 0.1853\n",
      "Epoch [4/10], Valid Accuracy: 93.7400, Valid Loss: 0.3279\n",
      "Epoch [5/10], Loss: 0.1829\n",
      "Epoch [5/10], Valid Accuracy: 95.4000, Valid Loss: 0.2197\n",
      "Epoch [6/10], Loss: 0.1661\n",
      "Epoch [6/10], Valid Accuracy: 95.2700, Valid Loss: 0.2463\n",
      "Epoch [7/10], Loss: 0.1626\n",
      "Epoch [7/10], Valid Accuracy: 95.0800, Valid Loss: 0.2564\n",
      "Epoch [8/10], Loss: 0.1574\n",
      "Epoch [8/10], Valid Accuracy: 94.9300, Valid Loss: 0.2815\n",
      "Epoch [9/10], Loss: 0.1625\n",
      "Epoch [9/10], Valid Accuracy: 95.0200, Valid Loss: 0.2737\n",
      "Epoch [10/10], Loss: 0.1448\n",
      "Epoch [10/10], Valid Accuracy: 95.3700, Valid Loss: 0.2935\n"
     ]
    }
   ],
   "source": [
    "M = [10, 50, 100, 300, 1000, 2000]\n",
    "lr=0.01\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "valid_acc  = []\n",
    "for m in M:\n",
    "    net = get_model(M=m)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "    _,_ ,trn_loss=train_model(train_loader, test_loader, num_epochs=10, model=net, optimizer=optimizer)\n",
    "    vld_acc,val_loss=model_accuracy_loss(net, test_loader)\n",
    "    valid_loss.append(val_loss)\n",
    "    train_loss.append(trn_loss)\n",
    "    valid_acc.append(vld_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa8122aa7b8>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa8122aa080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graph for train loss\n",
    "plt.plot(M,valid_loss)\n",
    "plt.plot(M,train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa811776e48>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa81179cc18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graph for validation loss\n",
    "plt.plot(M,valid_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M</th>\n",
       "      <th>vld_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>89.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>94.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>95.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>95.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000</td>\n",
       "      <td>95.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300</td>\n",
       "      <td>95.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      M  vld_acc\n",
       "0    10    89.12\n",
       "4  1000    94.82\n",
       "2   100    95.10\n",
       "1    50    95.21\n",
       "5  2000    95.37\n",
       "3   300    95.45"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'M':M,\n",
    "             'vld_acc': valid_acc}).sort_values(by='vld_acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here, we have the highest validation accuracy of 95.45%, when number of activations are 300. In the graph of validation loss, we can see that train loss decreases and increases slightly. This might be because for large number of neurons we would need more iterations to settle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To understand overfitting, look in the graph which plots train loss and validation loss Vs number of activations, I found that when number of activations in the hidden layer is more than 250, for a small decrease in training loss, the validation loss was increasing, This shows that there might be overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question No 3: Models with L2 regularization\n",
    "To add L2 regularization use the `weight_decay` argument on the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.2226\n",
      "Epoch [1/20], Valid Accuracy: 96.5300, Valid Loss: 0.1097\n",
      "Epoch [2/20], Loss: 0.0900\n",
      "Epoch [2/20], Valid Accuracy: 97.2600, Valid Loss: 0.0844\n",
      "Epoch [3/20], Loss: 0.0629\n",
      "Epoch [3/20], Valid Accuracy: 97.3400, Valid Loss: 0.0827\n",
      "Epoch [4/20], Loss: 0.0445\n",
      "Epoch [4/20], Valid Accuracy: 97.3900, Valid Loss: 0.0915\n",
      "Epoch [5/20], Loss: 0.0376\n",
      "Epoch [5/20], Valid Accuracy: 97.8200, Valid Loss: 0.0784\n",
      "Epoch [6/20], Loss: 0.0277\n",
      "Epoch [6/20], Valid Accuracy: 97.3400, Valid Loss: 0.0944\n",
      "Epoch [7/20], Loss: 0.0233\n",
      "Epoch [7/20], Valid Accuracy: 97.6800, Valid Loss: 0.0883\n",
      "Epoch [8/20], Loss: 0.0216\n",
      "Epoch [8/20], Valid Accuracy: 97.8500, Valid Loss: 0.0830\n",
      "Epoch [9/20], Loss: 0.0168\n",
      "Epoch [9/20], Valid Accuracy: 97.8300, Valid Loss: 0.0840\n",
      "Epoch [10/20], Loss: 0.0149\n",
      "Epoch [10/20], Valid Accuracy: 97.7000, Valid Loss: 0.0980\n",
      "Epoch [11/20], Loss: 0.0140\n",
      "Epoch [11/20], Valid Accuracy: 98.0500, Valid Loss: 0.0978\n",
      "Epoch [12/20], Loss: 0.0134\n",
      "Epoch [12/20], Valid Accuracy: 97.9900, Valid Loss: 0.0965\n",
      "Epoch [13/20], Loss: 0.0136\n",
      "Epoch [13/20], Valid Accuracy: 97.9700, Valid Loss: 0.0957\n",
      "Epoch [14/20], Loss: 0.0112\n",
      "Epoch [14/20], Valid Accuracy: 97.9900, Valid Loss: 0.0945\n",
      "Epoch [15/20], Loss: 0.0125\n",
      "Epoch [15/20], Valid Accuracy: 97.7800, Valid Loss: 0.1150\n",
      "Epoch [16/20], Loss: 0.0121\n",
      "Epoch [16/20], Valid Accuracy: 98.0600, Valid Loss: 0.0997\n",
      "Epoch [17/20], Loss: 0.0080\n",
      "Epoch [17/20], Valid Accuracy: 97.5600, Valid Loss: 0.1319\n",
      "Epoch [18/20], Loss: 0.0123\n",
      "Epoch [18/20], Valid Accuracy: 98.0500, Valid Loss: 0.1180\n",
      "Epoch [19/20], Loss: 0.0079\n",
      "Epoch [19/20], Valid Accuracy: 98.0000, Valid Loss: 0.1125\n",
      "Epoch [20/20], Loss: 0.0068\n",
      "Epoch [20/20], Valid Accuracy: 97.9700, Valid Loss: 0.1192\n",
      "Epoch [1/20], Loss: 0.2204\n",
      "Epoch [1/20], Valid Accuracy: 96.5400, Valid Loss: 0.1130\n",
      "Epoch [2/20], Loss: 0.0930\n",
      "Epoch [2/20], Valid Accuracy: 96.6800, Valid Loss: 0.1037\n",
      "Epoch [3/20], Loss: 0.0652\n",
      "Epoch [3/20], Valid Accuracy: 97.4500, Valid Loss: 0.0848\n",
      "Epoch [4/20], Loss: 0.0495\n",
      "Epoch [4/20], Valid Accuracy: 97.7000, Valid Loss: 0.0764\n",
      "Epoch [5/20], Loss: 0.0418\n",
      "Epoch [5/20], Valid Accuracy: 97.7300, Valid Loss: 0.0718\n",
      "Epoch [6/20], Loss: 0.0353\n",
      "Epoch [6/20], Valid Accuracy: 97.9000, Valid Loss: 0.0747\n",
      "Epoch [7/20], Loss: 0.0323\n",
      "Epoch [7/20], Valid Accuracy: 97.7600, Valid Loss: 0.0768\n",
      "Epoch [8/20], Loss: 0.0287\n",
      "Epoch [8/20], Valid Accuracy: 97.9300, Valid Loss: 0.0739\n",
      "Epoch [9/20], Loss: 0.0249\n",
      "Epoch [9/20], Valid Accuracy: 97.9500, Valid Loss: 0.0737\n",
      "Epoch [10/20], Loss: 0.0236\n",
      "Epoch [10/20], Valid Accuracy: 97.5400, Valid Loss: 0.0862\n",
      "Epoch [11/20], Loss: 0.0223\n",
      "Epoch [11/20], Valid Accuracy: 97.8600, Valid Loss: 0.0844\n",
      "Epoch [12/20], Loss: 0.0210\n",
      "Epoch [12/20], Valid Accuracy: 97.5900, Valid Loss: 0.0939\n",
      "Epoch [13/20], Loss: 0.0224\n",
      "Epoch [13/20], Valid Accuracy: 97.8300, Valid Loss: 0.0806\n",
      "Epoch [14/20], Loss: 0.0216\n",
      "Epoch [14/20], Valid Accuracy: 97.7900, Valid Loss: 0.0805\n",
      "Epoch [15/20], Loss: 0.0183\n",
      "Epoch [15/20], Valid Accuracy: 97.9800, Valid Loss: 0.0755\n",
      "Epoch [16/20], Loss: 0.0179\n",
      "Epoch [16/20], Valid Accuracy: 97.6600, Valid Loss: 0.0893\n",
      "Epoch [17/20], Loss: 0.0171\n",
      "Epoch [17/20], Valid Accuracy: 98.1200, Valid Loss: 0.0730\n",
      "Epoch [18/20], Loss: 0.0177\n",
      "Epoch [18/20], Valid Accuracy: 97.7900, Valid Loss: 0.0806\n",
      "Epoch [19/20], Loss: 0.0173\n",
      "Epoch [19/20], Valid Accuracy: 97.8600, Valid Loss: 0.0847\n",
      "Epoch [20/20], Loss: 0.0176\n",
      "Epoch [20/20], Valid Accuracy: 97.9700, Valid Loss: 0.0789\n",
      "Epoch [1/20], Loss: 0.2271\n",
      "Epoch [1/20], Valid Accuracy: 96.4100, Valid Loss: 0.1139\n",
      "Epoch [2/20], Loss: 0.1092\n",
      "Epoch [2/20], Valid Accuracy: 97.0300, Valid Loss: 0.0964\n",
      "Epoch [3/20], Loss: 0.0895\n",
      "Epoch [3/20], Valid Accuracy: 97.3700, Valid Loss: 0.0872\n",
      "Epoch [4/20], Loss: 0.0802\n",
      "Epoch [4/20], Valid Accuracy: 97.0700, Valid Loss: 0.0888\n",
      "Epoch [5/20], Loss: 0.0749\n",
      "Epoch [5/20], Valid Accuracy: 97.5400, Valid Loss: 0.0829\n",
      "Epoch [6/20], Loss: 0.0676\n",
      "Epoch [6/20], Valid Accuracy: 97.2800, Valid Loss: 0.0898\n",
      "Epoch [7/20], Loss: 0.0652\n",
      "Epoch [7/20], Valid Accuracy: 97.8300, Valid Loss: 0.0761\n",
      "Epoch [8/20], Loss: 0.0612\n",
      "Epoch [8/20], Valid Accuracy: 97.4800, Valid Loss: 0.0832\n",
      "Epoch [9/20], Loss: 0.0613\n",
      "Epoch [9/20], Valid Accuracy: 97.6800, Valid Loss: 0.0766\n",
      "Epoch [10/20], Loss: 0.0589\n",
      "Epoch [10/20], Valid Accuracy: 97.5800, Valid Loss: 0.0833\n",
      "Epoch [11/20], Loss: 0.0584\n",
      "Epoch [11/20], Valid Accuracy: 97.2200, Valid Loss: 0.0907\n",
      "Epoch [12/20], Loss: 0.0570\n",
      "Epoch [12/20], Valid Accuracy: 97.5900, Valid Loss: 0.0783\n",
      "Epoch [13/20], Loss: 0.0554\n",
      "Epoch [13/20], Valid Accuracy: 97.6600, Valid Loss: 0.0711\n",
      "Epoch [14/20], Loss: 0.0539\n",
      "Epoch [14/20], Valid Accuracy: 97.6600, Valid Loss: 0.0746\n",
      "Epoch [15/20], Loss: 0.0541\n",
      "Epoch [15/20], Valid Accuracy: 97.5100, Valid Loss: 0.0770\n",
      "Epoch [16/20], Loss: 0.0546\n",
      "Epoch [16/20], Valid Accuracy: 97.5000, Valid Loss: 0.0805\n",
      "Epoch [17/20], Loss: 0.0524\n",
      "Epoch [17/20], Valid Accuracy: 97.4500, Valid Loss: 0.0809\n",
      "Epoch [18/20], Loss: 0.0532\n",
      "Epoch [18/20], Valid Accuracy: 97.5000, Valid Loss: 0.0787\n",
      "Epoch [19/20], Loss: 0.0513\n",
      "Epoch [19/20], Valid Accuracy: 97.4500, Valid Loss: 0.0792\n",
      "Epoch [20/20], Loss: 0.0522\n",
      "Epoch [20/20], Valid Accuracy: 97.8300, Valid Loss: 0.0723\n",
      "Epoch [1/20], Loss: 0.2750\n",
      "Epoch [1/20], Valid Accuracy: 94.8600, Valid Loss: 0.1857\n",
      "Epoch [2/20], Loss: 0.1938\n",
      "Epoch [2/20], Valid Accuracy: 95.2000, Valid Loss: 0.1754\n",
      "Epoch [3/20], Loss: 0.1803\n",
      "Epoch [3/20], Valid Accuracy: 95.0500, Valid Loss: 0.1744\n",
      "Epoch [4/20], Loss: 0.1737\n",
      "Epoch [4/20], Valid Accuracy: 94.9000, Valid Loss: 0.1751\n",
      "Epoch [5/20], Loss: 0.1690\n",
      "Epoch [5/20], Valid Accuracy: 95.9100, Valid Loss: 0.1509\n",
      "Epoch [6/20], Loss: 0.1658\n",
      "Epoch [6/20], Valid Accuracy: 95.5700, Valid Loss: 0.1568\n",
      "Epoch [7/20], Loss: 0.1623\n",
      "Epoch [7/20], Valid Accuracy: 96.1600, Valid Loss: 0.1455\n",
      "Epoch [8/20], Loss: 0.1625\n",
      "Epoch [8/20], Valid Accuracy: 95.8400, Valid Loss: 0.1647\n",
      "Epoch [9/20], Loss: 0.1609\n",
      "Epoch [9/20], Valid Accuracy: 95.9700, Valid Loss: 0.1529\n",
      "Epoch [10/20], Loss: 0.1596\n",
      "Epoch [10/20], Valid Accuracy: 95.8300, Valid Loss: 0.1557\n",
      "Epoch [11/20], Loss: 0.1582\n",
      "Epoch [11/20], Valid Accuracy: 95.9400, Valid Loss: 0.1543\n",
      "Epoch [12/20], Loss: 0.1579\n",
      "Epoch [12/20], Valid Accuracy: 96.0300, Valid Loss: 0.1460\n",
      "Epoch [13/20], Loss: 0.1565\n",
      "Epoch [13/20], Valid Accuracy: 95.7900, Valid Loss: 0.1522\n",
      "Epoch [14/20], Loss: 0.1565\n",
      "Epoch [14/20], Valid Accuracy: 95.4500, Valid Loss: 0.1584\n",
      "Epoch [15/20], Loss: 0.1562\n",
      "Epoch [15/20], Valid Accuracy: 95.9300, Valid Loss: 0.1529\n",
      "Epoch [16/20], Loss: 0.1564\n",
      "Epoch [16/20], Valid Accuracy: 95.8800, Valid Loss: 0.1502\n",
      "Epoch [17/20], Loss: 0.1562\n",
      "Epoch [17/20], Valid Accuracy: 96.2600, Valid Loss: 0.1444\n",
      "Epoch [18/20], Loss: 0.1558\n",
      "Epoch [18/20], Valid Accuracy: 95.7400, Valid Loss: 0.1566\n",
      "Epoch [19/20], Loss: 0.1565\n",
      "Epoch [19/20], Valid Accuracy: 95.9400, Valid Loss: 0.1490\n",
      "Epoch [20/20], Loss: 0.1563\n",
      "Epoch [20/20], Valid Accuracy: 95.4700, Valid Loss: 0.1601\n",
      "Epoch [1/20], Loss: 0.5257\n",
      "Epoch [1/20], Valid Accuracy: 89.1800, Valid Loss: 0.4635\n",
      "Epoch [2/20], Loss: 0.4935\n",
      "Epoch [2/20], Valid Accuracy: 88.2900, Valid Loss: 0.4636\n",
      "Epoch [3/20], Loss: 0.4847\n",
      "Epoch [3/20], Valid Accuracy: 88.7500, Valid Loss: 0.4604\n",
      "Epoch [4/20], Loss: 0.4765\n",
      "Epoch [4/20], Valid Accuracy: 88.4700, Valid Loss: 0.4593\n",
      "Epoch [5/20], Loss: 0.4746\n",
      "Epoch [5/20], Valid Accuracy: 89.3700, Valid Loss: 0.4405\n",
      "Epoch [6/20], Loss: 0.4711\n",
      "Epoch [6/20], Valid Accuracy: 89.6700, Valid Loss: 0.4532\n",
      "Epoch [7/20], Loss: 0.4683\n",
      "Epoch [7/20], Valid Accuracy: 89.5900, Valid Loss: 0.4549\n",
      "Epoch [8/20], Loss: 0.4689\n",
      "Epoch [8/20], Valid Accuracy: 89.8300, Valid Loss: 0.4443\n",
      "Epoch [9/20], Loss: 0.4662\n",
      "Epoch [9/20], Valid Accuracy: 89.7800, Valid Loss: 0.4483\n",
      "Epoch [10/20], Loss: 0.4650\n",
      "Epoch [10/20], Valid Accuracy: 89.3500, Valid Loss: 0.4524\n",
      "Epoch [11/20], Loss: 0.4643\n",
      "Epoch [11/20], Valid Accuracy: 89.1200, Valid Loss: 0.4529\n",
      "Epoch [12/20], Loss: 0.4627\n",
      "Epoch [12/20], Valid Accuracy: 90.1300, Valid Loss: 0.4452\n",
      "Epoch [13/20], Loss: 0.4620\n",
      "Epoch [13/20], Valid Accuracy: 89.3300, Valid Loss: 0.4457\n",
      "Epoch [14/20], Loss: 0.4630\n",
      "Epoch [14/20], Valid Accuracy: 90.1200, Valid Loss: 0.4398\n",
      "Epoch [15/20], Loss: 0.4618\n",
      "Epoch [15/20], Valid Accuracy: 89.1800, Valid Loss: 0.4466\n",
      "Epoch [16/20], Loss: 0.4609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Valid Accuracy: 89.8700, Valid Loss: 0.4415\n",
      "Epoch [17/20], Loss: 0.4624\n",
      "Epoch [17/20], Valid Accuracy: 89.6700, Valid Loss: 0.4493\n",
      "Epoch [18/20], Loss: 0.4611\n",
      "Epoch [18/20], Valid Accuracy: 90.0100, Valid Loss: 0.4368\n",
      "Epoch [19/20], Loss: 0.4611\n",
      "Epoch [19/20], Valid Accuracy: 90.2300, Valid Loss: 0.4382\n",
      "Epoch [20/20], Loss: 0.4604\n",
      "Epoch [20/20], Valid Accuracy: 89.6800, Valid Loss: 0.4427\n",
      "Epoch [1/20], Loss: 0.8598\n",
      "Epoch [1/20], Valid Accuracy: 82.9900, Valid Loss: 0.8119\n",
      "Epoch [2/20], Loss: 0.8377\n",
      "Epoch [2/20], Valid Accuracy: 83.1500, Valid Loss: 0.8169\n",
      "Epoch [3/20], Loss: 0.8327\n",
      "Epoch [3/20], Valid Accuracy: 82.3200, Valid Loss: 0.8207\n",
      "Epoch [4/20], Loss: 0.8265\n",
      "Epoch [4/20], Valid Accuracy: 84.7300, Valid Loss: 0.8163\n",
      "Epoch [5/20], Loss: 0.8240\n",
      "Epoch [5/20], Valid Accuracy: 86.2200, Valid Loss: 0.8013\n",
      "Epoch [6/20], Loss: 0.8202\n",
      "Epoch [6/20], Valid Accuracy: 84.4500, Valid Loss: 0.7882\n",
      "Epoch [7/20], Loss: 0.8179\n",
      "Epoch [7/20], Valid Accuracy: 86.4200, Valid Loss: 0.7886\n",
      "Epoch [8/20], Loss: 0.8151\n",
      "Epoch [8/20], Valid Accuracy: 85.4200, Valid Loss: 0.8158\n",
      "Epoch [9/20], Loss: 0.8153\n",
      "Epoch [9/20], Valid Accuracy: 85.9000, Valid Loss: 0.8001\n",
      "Epoch [10/20], Loss: 0.8140\n",
      "Epoch [10/20], Valid Accuracy: 85.4500, Valid Loss: 0.7968\n",
      "Epoch [11/20], Loss: 0.8132\n",
      "Epoch [11/20], Valid Accuracy: 85.1200, Valid Loss: 0.7866\n",
      "Epoch [12/20], Loss: 0.8126\n",
      "Epoch [12/20], Valid Accuracy: 84.8300, Valid Loss: 0.7907\n",
      "Epoch [13/20], Loss: 0.8127\n",
      "Epoch [13/20], Valid Accuracy: 85.8100, Valid Loss: 0.7867\n",
      "Epoch [14/20], Loss: 0.8124\n",
      "Epoch [14/20], Valid Accuracy: 83.6300, Valid Loss: 0.7898\n",
      "Epoch [15/20], Loss: 0.8126\n",
      "Epoch [15/20], Valid Accuracy: 84.9500, Valid Loss: 0.7959\n",
      "Epoch [16/20], Loss: 0.8133\n",
      "Epoch [16/20], Valid Accuracy: 85.2600, Valid Loss: 0.7909\n",
      "Epoch [17/20], Loss: 0.8127\n",
      "Epoch [17/20], Valid Accuracy: 85.0600, Valid Loss: 0.7875\n",
      "Epoch [18/20], Loss: 0.8109\n",
      "Epoch [18/20], Valid Accuracy: 85.2400, Valid Loss: 0.7940\n",
      "Epoch [19/20], Loss: 0.8101\n",
      "Epoch [19/20], Valid Accuracy: 85.3500, Valid Loss: 0.7907\n",
      "Epoch [20/20], Loss: 0.8104\n",
      "Epoch [20/20], Valid Accuracy: 84.5600, Valid Loss: 0.7989\n"
     ]
    }
   ],
   "source": [
    "M = 300\n",
    "lr= 0.001\n",
    "wd = [0, 0.0001, 0.001, 0.01, 0.1, 0.3]\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "valid_acc  = []\n",
    "for w in wd:\n",
    "    net = get_model(M)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr,weight_decay=w)\n",
    "    val_acc, val_loss, trn_loss=train_model(train_loader, test_loader, num_epochs=20, model=net, optimizer=optimizer)\n",
    "    valid_acc.append(val_acc)\n",
    "    valid_loss.append(val_loss)\n",
    "    train_loss.append(trn_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa8117a86d8>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa8117a8940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# graph for train and validation loss Vs weight decay\n",
    "plt.plot(wd,valid_loss)\n",
    "plt.plot(wd,train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa8116d4c18>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBeX9usWBkCeyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa81174be10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#graph  for validation accuracy Vs weight decay\n",
    "plt.plot(wd,valid_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wt decay</th>\n",
       "      <th>vld_acc</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.3000</td>\n",
       "      <td>84.56</td>\n",
       "      <td>0.006774</td>\n",
       "      <td>0.119176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>89.68</td>\n",
       "      <td>0.017598</td>\n",
       "      <td>0.078918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>95.47</td>\n",
       "      <td>0.052169</td>\n",
       "      <td>0.072291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>97.83</td>\n",
       "      <td>0.156282</td>\n",
       "      <td>0.160092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>97.97</td>\n",
       "      <td>0.460367</td>\n",
       "      <td>0.442726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>97.97</td>\n",
       "      <td>0.810427</td>\n",
       "      <td>0.798943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    wt decay  vld_acc  train_loss  valid_loss\n",
       "5     0.3000    84.56    0.006774    0.119176\n",
       "4     0.1000    89.68    0.017598    0.078918\n",
       "3     0.0100    95.47    0.052169    0.072291\n",
       "2     0.0010    97.83    0.156282    0.160092\n",
       "0     0.0000    97.97    0.460367    0.442726\n",
       "1     0.0001    97.97    0.810427    0.798943"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p =pd.DataFrame({' wt decay':wd,\n",
    "             'vld_acc': valid_acc}).sort_values(by='vld_acc')\n",
    "p['train_loss'] = train_loss\n",
    "p['valid_loss'] = valid_loss\n",
    "p.sort_values(by='vld_acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the model performs better without weight decay compared to weight decay. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question No 4 : Models with Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_v2(M = 300, p=0):\n",
    "    modules = []\n",
    "    modules.append(nn.Linear(28*28, M))\n",
    "    modules.append(nn.ReLU())\n",
    "    if p > 0:\n",
    "        modules.append(nn.Dropout(p))\n",
    "    modules.append(nn.Linear(M, 10))\n",
    "    return nn.Sequential(*modules).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.2187\n",
      "Epoch [1/20], Valid Accuracy: 96.8300, Valid Loss: 0.1085\n",
      "Epoch [2/20], Loss: 0.0892\n",
      "Epoch [2/20], Valid Accuracy: 97.3700, Valid Loss: 0.0832\n",
      "Epoch [3/20], Loss: 0.0607\n",
      "Epoch [3/20], Valid Accuracy: 97.6100, Valid Loss: 0.0777\n",
      "Epoch [4/20], Loss: 0.0446\n",
      "Epoch [4/20], Valid Accuracy: 97.9800, Valid Loss: 0.0676\n",
      "Epoch [5/20], Loss: 0.0334\n",
      "Epoch [5/20], Valid Accuracy: 97.7500, Valid Loss: 0.0782\n",
      "Epoch [6/20], Loss: 0.0295\n",
      "Epoch [6/20], Valid Accuracy: 97.6600, Valid Loss: 0.0778\n",
      "Epoch [7/20], Loss: 0.0232\n",
      "Epoch [7/20], Valid Accuracy: 97.6200, Valid Loss: 0.0782\n",
      "Epoch [8/20], Loss: 0.0219\n",
      "Epoch [8/20], Valid Accuracy: 97.8600, Valid Loss: 0.0799\n",
      "Epoch [9/20], Loss: 0.0173\n",
      "Epoch [9/20], Valid Accuracy: 97.8100, Valid Loss: 0.0954\n",
      "Epoch [10/20], Loss: 0.0160\n",
      "Epoch [10/20], Valid Accuracy: 97.8600, Valid Loss: 0.0913\n",
      "Epoch [11/20], Loss: 0.0118\n",
      "Epoch [11/20], Valid Accuracy: 97.8800, Valid Loss: 0.0935\n",
      "Epoch [12/20], Loss: 0.0142\n",
      "Epoch [12/20], Valid Accuracy: 97.8700, Valid Loss: 0.0949\n",
      "Epoch [13/20], Loss: 0.0152\n",
      "Epoch [13/20], Valid Accuracy: 97.6300, Valid Loss: 0.1073\n",
      "Epoch [14/20], Loss: 0.0112\n",
      "Epoch [14/20], Valid Accuracy: 97.7800, Valid Loss: 0.1087\n",
      "Epoch [15/20], Loss: 0.0135\n",
      "Epoch [15/20], Valid Accuracy: 98.0700, Valid Loss: 0.0957\n",
      "Epoch [16/20], Loss: 0.0070\n",
      "Epoch [16/20], Valid Accuracy: 97.8700, Valid Loss: 0.1162\n",
      "Epoch [17/20], Loss: 0.0107\n",
      "Epoch [17/20], Valid Accuracy: 97.6100, Valid Loss: 0.1365\n",
      "Epoch [18/20], Loss: 0.0110\n",
      "Epoch [18/20], Valid Accuracy: 97.8000, Valid Loss: 0.1186\n",
      "Epoch [19/20], Loss: 0.0125\n",
      "Epoch [19/20], Valid Accuracy: 98.1100, Valid Loss: 0.1118\n",
      "Epoch [20/20], Loss: 0.0073\n",
      "Epoch [20/20], Valid Accuracy: 98.0400, Valid Loss: 0.1108\n",
      "Epoch [1/20], Loss: 0.2419\n",
      "Epoch [1/20], Valid Accuracy: 96.6400, Valid Loss: 0.1116\n",
      "Epoch [2/20], Loss: 0.1105\n",
      "Epoch [2/20], Valid Accuracy: 97.2500, Valid Loss: 0.0891\n",
      "Epoch [3/20], Loss: 0.0847\n",
      "Epoch [3/20], Valid Accuracy: 97.6600, Valid Loss: 0.0776\n",
      "Epoch [4/20], Loss: 0.0677\n",
      "Epoch [4/20], Valid Accuracy: 97.6000, Valid Loss: 0.0814\n",
      "Epoch [5/20], Loss: 0.0599\n",
      "Epoch [5/20], Valid Accuracy: 97.8900, Valid Loss: 0.0762\n",
      "Epoch [6/20], Loss: 0.0508\n",
      "Epoch [6/20], Valid Accuracy: 97.7800, Valid Loss: 0.0771\n",
      "Epoch [7/20], Loss: 0.0442\n",
      "Epoch [7/20], Valid Accuracy: 97.8600, Valid Loss: 0.0752\n",
      "Epoch [8/20], Loss: 0.0409\n",
      "Epoch [8/20], Valid Accuracy: 97.9100, Valid Loss: 0.0741\n",
      "Epoch [9/20], Loss: 0.0393\n",
      "Epoch [9/20], Valid Accuracy: 98.0100, Valid Loss: 0.0779\n",
      "Epoch [10/20], Loss: 0.0317\n",
      "Epoch [10/20], Valid Accuracy: 98.2900, Valid Loss: 0.0729\n",
      "Epoch [11/20], Loss: 0.0311\n",
      "Epoch [11/20], Valid Accuracy: 98.2100, Valid Loss: 0.0782\n",
      "Epoch [12/20], Loss: 0.0278\n",
      "Epoch [12/20], Valid Accuracy: 97.8700, Valid Loss: 0.0919\n",
      "Epoch [13/20], Loss: 0.0292\n",
      "Epoch [13/20], Valid Accuracy: 98.1200, Valid Loss: 0.0779\n",
      "Epoch [14/20], Loss: 0.0285\n",
      "Epoch [14/20], Valid Accuracy: 98.3300, Valid Loss: 0.0765\n",
      "Epoch [15/20], Loss: 0.0256\n",
      "Epoch [15/20], Valid Accuracy: 98.1900, Valid Loss: 0.0868\n",
      "Epoch [16/20], Loss: 0.0263\n",
      "Epoch [16/20], Valid Accuracy: 98.2000, Valid Loss: 0.0929\n",
      "Epoch [17/20], Loss: 0.0257\n",
      "Epoch [17/20], Valid Accuracy: 98.0500, Valid Loss: 0.0927\n",
      "Epoch [18/20], Loss: 0.0235\n",
      "Epoch [18/20], Valid Accuracy: 98.3900, Valid Loss: 0.0806\n",
      "Epoch [19/20], Loss: 0.0219\n",
      "Epoch [19/20], Valid Accuracy: 98.2200, Valid Loss: 0.1052\n",
      "Epoch [20/20], Loss: 0.0240\n",
      "Epoch [20/20], Valid Accuracy: 98.3400, Valid Loss: 0.0888\n",
      "Epoch [1/20], Loss: 0.2810\n",
      "Epoch [1/20], Valid Accuracy: 95.8000, Valid Loss: 0.1341\n",
      "Epoch [2/20], Loss: 0.1439\n",
      "Epoch [2/20], Valid Accuracy: 97.1000, Valid Loss: 0.0938\n",
      "Epoch [3/20], Loss: 0.1146\n",
      "Epoch [3/20], Valid Accuracy: 97.6200, Valid Loss: 0.0794\n",
      "Epoch [4/20], Loss: 0.1005\n",
      "Epoch [4/20], Valid Accuracy: 97.7300, Valid Loss: 0.0734\n",
      "Epoch [5/20], Loss: 0.0889\n",
      "Epoch [5/20], Valid Accuracy: 97.7200, Valid Loss: 0.0766\n",
      "Epoch [6/20], Loss: 0.0790\n",
      "Epoch [6/20], Valid Accuracy: 97.7100, Valid Loss: 0.0772\n",
      "Epoch [7/20], Loss: 0.0715\n",
      "Epoch [7/20], Valid Accuracy: 97.8800, Valid Loss: 0.0698\n",
      "Epoch [8/20], Loss: 0.0707\n",
      "Epoch [8/20], Valid Accuracy: 97.9300, Valid Loss: 0.0720\n",
      "Epoch [9/20], Loss: 0.0633\n",
      "Epoch [9/20], Valid Accuracy: 98.1100, Valid Loss: 0.0724\n",
      "Epoch [10/20], Loss: 0.0606\n",
      "Epoch [10/20], Valid Accuracy: 98.0700, Valid Loss: 0.0697\n",
      "Epoch [11/20], Loss: 0.0591\n",
      "Epoch [11/20], Valid Accuracy: 98.2800, Valid Loss: 0.0681\n",
      "Epoch [12/20], Loss: 0.0557\n",
      "Epoch [12/20], Valid Accuracy: 97.9800, Valid Loss: 0.0756\n",
      "Epoch [13/20], Loss: 0.0570\n",
      "Epoch [13/20], Valid Accuracy: 97.9400, Valid Loss: 0.0780\n",
      "Epoch [14/20], Loss: 0.0512\n",
      "Epoch [14/20], Valid Accuracy: 98.1700, Valid Loss: 0.0714\n",
      "Epoch [15/20], Loss: 0.0496\n",
      "Epoch [15/20], Valid Accuracy: 97.9900, Valid Loss: 0.0795\n",
      "Epoch [16/20], Loss: 0.0515\n",
      "Epoch [16/20], Valid Accuracy: 98.0700, Valid Loss: 0.0744\n",
      "Epoch [17/20], Loss: 0.0460\n",
      "Epoch [17/20], Valid Accuracy: 98.0700, Valid Loss: 0.0731\n",
      "Epoch [18/20], Loss: 0.0452\n",
      "Epoch [18/20], Valid Accuracy: 98.1700, Valid Loss: 0.0802\n",
      "Epoch [19/20], Loss: 0.0439\n",
      "Epoch [19/20], Valid Accuracy: 98.1500, Valid Loss: 0.0758\n",
      "Epoch [20/20], Loss: 0.0425\n",
      "Epoch [20/20], Valid Accuracy: 98.0400, Valid Loss: 0.0893\n",
      "Epoch [1/20], Loss: 0.3429\n",
      "Epoch [1/20], Valid Accuracy: 95.4700, Valid Loss: 0.1467\n",
      "Epoch [2/20], Loss: 0.1998\n",
      "Epoch [2/20], Valid Accuracy: 96.6800, Valid Loss: 0.1083\n",
      "Epoch [3/20], Loss: 0.1688\n",
      "Epoch [3/20], Valid Accuracy: 97.1100, Valid Loss: 0.0921\n",
      "Epoch [4/20], Loss: 0.1576\n",
      "Epoch [4/20], Valid Accuracy: 97.2100, Valid Loss: 0.0908\n",
      "Epoch [5/20], Loss: 0.1438\n",
      "Epoch [5/20], Valid Accuracy: 97.4800, Valid Loss: 0.0849\n",
      "Epoch [6/20], Loss: 0.1335\n",
      "Epoch [6/20], Valid Accuracy: 97.4900, Valid Loss: 0.0853\n",
      "Epoch [7/20], Loss: 0.1276\n",
      "Epoch [7/20], Valid Accuracy: 97.4500, Valid Loss: 0.0873\n",
      "Epoch [8/20], Loss: 0.1273\n",
      "Epoch [8/20], Valid Accuracy: 97.7200, Valid Loss: 0.0751\n",
      "Epoch [9/20], Loss: 0.1187\n",
      "Epoch [9/20], Valid Accuracy: 97.8400, Valid Loss: 0.0791\n",
      "Epoch [10/20], Loss: 0.1159\n",
      "Epoch [10/20], Valid Accuracy: 97.8300, Valid Loss: 0.0753\n",
      "Epoch [11/20], Loss: 0.1110\n",
      "Epoch [11/20], Valid Accuracy: 97.9800, Valid Loss: 0.0741\n",
      "Epoch [12/20], Loss: 0.1088\n",
      "Epoch [12/20], Valid Accuracy: 97.9600, Valid Loss: 0.0753\n",
      "Epoch [13/20], Loss: 0.1042\n",
      "Epoch [13/20], Valid Accuracy: 97.9400, Valid Loss: 0.0767\n",
      "Epoch [14/20], Loss: 0.1041\n",
      "Epoch [14/20], Valid Accuracy: 98.1300, Valid Loss: 0.0705\n",
      "Epoch [15/20], Loss: 0.1001\n",
      "Epoch [15/20], Valid Accuracy: 98.2800, Valid Loss: 0.0707\n",
      "Epoch [16/20], Loss: 0.0986\n",
      "Epoch [16/20], Valid Accuracy: 98.1700, Valid Loss: 0.0749\n",
      "Epoch [17/20], Loss: 0.0983\n",
      "Epoch [17/20], Valid Accuracy: 97.9700, Valid Loss: 0.0766\n",
      "Epoch [18/20], Loss: 0.0935\n",
      "Epoch [18/20], Valid Accuracy: 98.0000, Valid Loss: 0.0791\n",
      "Epoch [19/20], Loss: 0.0942\n",
      "Epoch [19/20], Valid Accuracy: 97.9800, Valid Loss: 0.0846\n",
      "Epoch [20/20], Loss: 0.0887\n",
      "Epoch [20/20], Valid Accuracy: 97.9900, Valid Loss: 0.0797\n",
      "Epoch [1/20], Loss: 0.5153\n",
      "Epoch [1/20], Valid Accuracy: 94.2600, Valid Loss: 0.1872\n",
      "Epoch [2/20], Loss: 0.3532\n",
      "Epoch [2/20], Valid Accuracy: 95.3100, Valid Loss: 0.1541\n",
      "Epoch [3/20], Loss: 0.3238\n",
      "Epoch [3/20], Valid Accuracy: 95.9000, Valid Loss: 0.1398\n",
      "Epoch [4/20], Loss: 0.3057\n",
      "Epoch [4/20], Valid Accuracy: 96.0400, Valid Loss: 0.1298\n",
      "Epoch [5/20], Loss: 0.2930\n",
      "Epoch [5/20], Valid Accuracy: 96.6200, Valid Loss: 0.1187\n",
      "Epoch [6/20], Loss: 0.2845\n",
      "Epoch [6/20], Valid Accuracy: 96.5800, Valid Loss: 0.1169\n",
      "Epoch [7/20], Loss: 0.2756\n",
      "Epoch [7/20], Valid Accuracy: 96.8100, Valid Loss: 0.1123\n",
      "Epoch [8/20], Loss: 0.2663\n",
      "Epoch [8/20], Valid Accuracy: 96.7600, Valid Loss: 0.1143\n",
      "Epoch [9/20], Loss: 0.2574\n",
      "Epoch [9/20], Valid Accuracy: 97.0400, Valid Loss: 0.1061\n",
      "Epoch [10/20], Loss: 0.2549\n",
      "Epoch [10/20], Valid Accuracy: 97.1100, Valid Loss: 0.1058\n",
      "Epoch [11/20], Loss: 0.2532\n",
      "Epoch [11/20], Valid Accuracy: 97.1100, Valid Loss: 0.1046\n",
      "Epoch [12/20], Loss: 0.2486\n",
      "Epoch [12/20], Valid Accuracy: 96.9200, Valid Loss: 0.1038\n",
      "Epoch [13/20], Loss: 0.2439\n",
      "Epoch [13/20], Valid Accuracy: 97.1900, Valid Loss: 0.0999\n",
      "Epoch [14/20], Loss: 0.2429\n",
      "Epoch [14/20], Valid Accuracy: 97.1100, Valid Loss: 0.1007\n",
      "Epoch [15/20], Loss: 0.2444\n",
      "Epoch [15/20], Valid Accuracy: 97.0300, Valid Loss: 0.1024\n",
      "Epoch [16/20], Loss: 0.2346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Valid Accuracy: 97.4700, Valid Loss: 0.1003\n",
      "Epoch [17/20], Loss: 0.2338\n",
      "Epoch [17/20], Valid Accuracy: 97.2500, Valid Loss: 0.1000\n",
      "Epoch [18/20], Loss: 0.2296\n",
      "Epoch [18/20], Valid Accuracy: 97.2000, Valid Loss: 0.1048\n",
      "Epoch [19/20], Loss: 0.2285\n",
      "Epoch [19/20], Valid Accuracy: 97.3700, Valid Loss: 0.0991\n",
      "Epoch [20/20], Loss: 0.2295\n",
      "Epoch [20/20], Valid Accuracy: 97.2800, Valid Loss: 0.1017\n",
      "Epoch [1/20], Loss: 2.3017\n",
      "Epoch [1/20], Valid Accuracy: 11.1900, Valid Loss: 2.3099\n",
      "Epoch [2/20], Loss: 2.3013\n",
      "Epoch [2/20], Valid Accuracy: 11.3400, Valid Loss: 2.3110\n",
      "Epoch [3/20], Loss: 2.3013\n",
      "Epoch [3/20], Valid Accuracy: 11.2000, Valid Loss: 2.3104\n",
      "Epoch [4/20], Loss: 2.3013\n",
      "Epoch [4/20], Valid Accuracy: 11.1100, Valid Loss: 2.3111\n",
      "Epoch [5/20], Loss: 2.3013\n",
      "Epoch [5/20], Valid Accuracy: 10.9300, Valid Loss: 2.3109\n",
      "Epoch [6/20], Loss: 2.3013\n",
      "Epoch [6/20], Valid Accuracy: 11.3300, Valid Loss: 2.3107\n",
      "Epoch [7/20], Loss: 2.3013\n",
      "Epoch [7/20], Valid Accuracy: 11.2800, Valid Loss: 2.3114\n",
      "Epoch [8/20], Loss: 2.3013\n",
      "Epoch [8/20], Valid Accuracy: 11.3000, Valid Loss: 2.3109\n",
      "Epoch [9/20], Loss: 2.3013\n",
      "Epoch [9/20], Valid Accuracy: 11.1600, Valid Loss: 2.3110\n",
      "Epoch [10/20], Loss: 2.3013\n",
      "Epoch [10/20], Valid Accuracy: 11.4800, Valid Loss: 2.3104\n",
      "Epoch [11/20], Loss: 2.3013\n",
      "Epoch [11/20], Valid Accuracy: 11.4000, Valid Loss: 2.3108\n",
      "Epoch [12/20], Loss: 2.3013\n",
      "Epoch [12/20], Valid Accuracy: 11.2700, Valid Loss: 2.3107\n",
      "Epoch [13/20], Loss: 2.3013\n",
      "Epoch [13/20], Valid Accuracy: 11.0800, Valid Loss: 2.3110\n",
      "Epoch [14/20], Loss: 2.3013\n",
      "Epoch [14/20], Valid Accuracy: 11.3500, Valid Loss: 2.3107\n",
      "Epoch [15/20], Loss: 2.3013\n",
      "Epoch [15/20], Valid Accuracy: 11.2300, Valid Loss: 2.3108\n",
      "Epoch [16/20], Loss: 2.3013\n",
      "Epoch [16/20], Valid Accuracy: 11.1600, Valid Loss: 2.3105\n",
      "Epoch [17/20], Loss: 2.3013\n",
      "Epoch [17/20], Valid Accuracy: 11.3900, Valid Loss: 2.3109\n",
      "Epoch [18/20], Loss: 2.3013\n",
      "Epoch [18/20], Valid Accuracy: 11.5000, Valid Loss: 2.3113\n",
      "Epoch [19/20], Loss: 2.3013\n",
      "Epoch [19/20], Valid Accuracy: 11.1700, Valid Loss: 2.3106\n",
      "Epoch [20/20], Loss: 2.3013\n",
      "Epoch [20/20], Valid Accuracy: 11.2900, Valid Loss: 2.3111\n"
     ]
    }
   ],
   "source": [
    "M = 300\n",
    "lr= 0.001\n",
    "drp_out = [0, 0.2, 0.4, 0.6, 0.8, 1]\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "valid_acc  = []\n",
    "for d in drp_out:\n",
    "    net = get_model_v2(M,p=d)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "    val_acc, val_loss, trn_loss=train_model(train_loader, test_loader, num_epochs=20, model=net, optimizer=optimizer)\n",
    "    valid_acc.append(val_acc)\n",
    "    valid_loss.append(val_loss)\n",
    "    train_loss.append(trn_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa999282a58>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa999282b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(drp_out,valid_loss)\n",
    "plt.plot(drp_out,train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa994052128>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrBUR+eoOIgYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa9940777f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(drp_out,valid_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drop out rate</th>\n",
       "      <th>vld_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8</td>\n",
       "      <td>97.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6</td>\n",
       "      <td>97.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>98.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4</td>\n",
       "      <td>98.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>98.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    drop out rate  vld_acc\n",
       "5             1.0    11.29\n",
       "4             0.8    97.28\n",
       "3             0.6    97.99\n",
       "0             0.0    98.04\n",
       "2             0.4    98.04\n",
       "1             0.2    98.34"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = pd.DataFrame({' drop out rate':drp_out,\n",
    "             'vld_acc': valid_acc}).sort_values(by='vld_acc')\n",
    "p['train_loss'] = train_loss\n",
    "p['valid_loss'] = valid_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have considered different dropouts ranging from 0 to1. The highest validation accuracy is achieved with drop out rate of 0.2 in layer 1 and zero drop out rate in layer 2. Compared to weight decay, dropout helps to improve testing accuracy, weight decay didnot improve model performace infact reduced the model performace. But with a dropout rate of 0.2, the validation accuracy increased to 98.34%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 : 3 Layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_v2(M, p):  \n",
    "    modules = []\n",
    "    modules.append(nn.Linear(28*28, M[0]))\n",
    "    modules.append(nn.ReLU())\n",
    "    if p[0] > 0: modules.append(nn.Dropout(p[0]))\n",
    "    modules.append(nn.Linear(M[0], M[1]))\n",
    "    modules.append(nn.ReLU())\n",
    "    if p[1] > 0: modules.append(nn.Dropout(p[1]))\n",
    "    modules.append(nn.Linear(M[1], 10))\n",
    "    return nn.Sequential(*modules).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment, I tune my 3-layer network in the following order. <br>\n",
    "1.Architecture finalisation <br>\n",
    "2.Learning rate tuning <br>\n",
    "3.dropout <br>\n",
    "4.weight decay<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is run on a grid by all the combination of M1 and M2. Here, the values for the experiment were selected from the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'M1':[300,500],\n",
    "              'M2':[100,150,500]\n",
    "             }\n",
    "p = list(ParameterGrid(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.2912\n",
      "Epoch [1/20], Valid Accuracy: 94.2600, Valid Loss: 0.2110\n",
      "Epoch [2/20], Loss: 0.1901\n",
      "Epoch [2/20], Valid Accuracy: 94.9000, Valid Loss: 0.1990\n",
      "Epoch [3/20], Loss: 0.1755\n",
      "Epoch [3/20], Valid Accuracy: 94.7400, Valid Loss: 0.2046\n",
      "Epoch [4/20], Loss: 0.1613\n",
      "Epoch [4/20], Valid Accuracy: 95.3600, Valid Loss: 0.1959\n",
      "Epoch [5/20], Loss: 0.1441\n",
      "Epoch [5/20], Valid Accuracy: 95.9200, Valid Loss: 0.1651\n",
      "Epoch [6/20], Loss: 0.1468\n",
      "Epoch [6/20], Valid Accuracy: 95.3500, Valid Loss: 0.2024\n",
      "Epoch [7/20], Loss: 0.1315\n",
      "Epoch [7/20], Valid Accuracy: 96.4100, Valid Loss: 0.1764\n",
      "Epoch [8/20], Loss: 0.1365\n",
      "Epoch [8/20], Valid Accuracy: 96.6000, Valid Loss: 0.1603\n",
      "Epoch [9/20], Loss: 0.1305\n",
      "Epoch [9/20], Valid Accuracy: 96.3000, Valid Loss: 0.1926\n",
      "Epoch [10/20], Loss: 0.1175\n",
      "Epoch [10/20], Valid Accuracy: 95.9400, Valid Loss: 0.1958\n",
      "Epoch [11/20], Loss: 0.1197\n",
      "Epoch [11/20], Valid Accuracy: 96.0700, Valid Loss: 0.1873\n",
      "Epoch [12/20], Loss: 0.1174\n",
      "Epoch [12/20], Valid Accuracy: 96.1100, Valid Loss: 0.2316\n",
      "Epoch [13/20], Loss: 0.1139\n",
      "Epoch [13/20], Valid Accuracy: 96.2400, Valid Loss: 0.2092\n",
      "Epoch [14/20], Loss: 0.1154\n",
      "Epoch [14/20], Valid Accuracy: 96.0000, Valid Loss: 0.2348\n",
      "Epoch [15/20], Loss: 0.1028\n",
      "Epoch [15/20], Valid Accuracy: 96.5600, Valid Loss: 0.1980\n",
      "Epoch [16/20], Loss: 0.1025\n",
      "Epoch [16/20], Valid Accuracy: 96.0200, Valid Loss: 0.2326\n",
      "Epoch [17/20], Loss: 0.1084\n",
      "Epoch [17/20], Valid Accuracy: 96.7000, Valid Loss: 0.1965\n",
      "Epoch [18/20], Loss: 0.1149\n",
      "Epoch [18/20], Valid Accuracy: 96.3200, Valid Loss: 0.2474\n",
      "Epoch [19/20], Loss: 0.1164\n",
      "Epoch [19/20], Valid Accuracy: 96.2600, Valid Loss: 0.2064\n",
      "Epoch [20/20], Loss: 0.1059\n",
      "Epoch [20/20], Valid Accuracy: 96.6300, Valid Loss: 0.2197\n",
      "Done\n",
      "Epoch [1/20], Loss: 0.2953\n",
      "Epoch [1/20], Valid Accuracy: 93.1100, Valid Loss: 0.2264\n",
      "Epoch [2/20], Loss: 0.2115\n",
      "Epoch [2/20], Valid Accuracy: 95.1200, Valid Loss: 0.2061\n",
      "Epoch [3/20], Loss: 0.1809\n",
      "Epoch [3/20], Valid Accuracy: 95.2000, Valid Loss: 0.1865\n",
      "Epoch [4/20], Loss: 0.1652\n",
      "Epoch [4/20], Valid Accuracy: 94.8800, Valid Loss: 0.2498\n",
      "Epoch [5/20], Loss: 0.1618\n",
      "Epoch [5/20], Valid Accuracy: 95.4900, Valid Loss: 0.1802\n",
      "Epoch [6/20], Loss: 0.1461\n",
      "Epoch [6/20], Valid Accuracy: 94.4700, Valid Loss: 0.2515\n",
      "Epoch [7/20], Loss: 0.1437\n",
      "Epoch [7/20], Valid Accuracy: 95.2500, Valid Loss: 0.2613\n",
      "Epoch [8/20], Loss: 0.1509\n",
      "Epoch [8/20], Valid Accuracy: 96.4400, Valid Loss: 0.1774\n",
      "Epoch [9/20], Loss: 0.1382\n",
      "Epoch [9/20], Valid Accuracy: 95.3900, Valid Loss: 0.2189\n",
      "Epoch [10/20], Loss: 0.1313\n",
      "Epoch [10/20], Valid Accuracy: 96.1700, Valid Loss: 0.1975\n",
      "Epoch [11/20], Loss: 0.1203\n",
      "Epoch [11/20], Valid Accuracy: 96.5300, Valid Loss: 0.1912\n",
      "Epoch [12/20], Loss: 0.1236\n",
      "Epoch [12/20], Valid Accuracy: 95.5700, Valid Loss: 0.2392\n",
      "Epoch [13/20], Loss: 0.1159\n",
      "Epoch [13/20], Valid Accuracy: 96.6600, Valid Loss: 0.1940\n",
      "Epoch [14/20], Loss: 0.1118\n",
      "Epoch [14/20], Valid Accuracy: 96.7300, Valid Loss: 0.1693\n",
      "Epoch [15/20], Loss: 0.1102\n",
      "Epoch [15/20], Valid Accuracy: 95.9700, Valid Loss: 0.2290\n",
      "Epoch [16/20], Loss: 0.1136\n",
      "Epoch [16/20], Valid Accuracy: 96.3500, Valid Loss: 0.2543\n",
      "Epoch [17/20], Loss: 0.1010\n",
      "Epoch [17/20], Valid Accuracy: 96.2300, Valid Loss: 0.2480\n",
      "Epoch [18/20], Loss: 0.1205\n",
      "Epoch [18/20], Valid Accuracy: 96.0300, Valid Loss: 0.2402\n",
      "Epoch [19/20], Loss: 0.1152\n",
      "Epoch [19/20], Valid Accuracy: 96.6400, Valid Loss: 0.2005\n",
      "Epoch [20/20], Loss: 0.1078\n",
      "Epoch [20/20], Valid Accuracy: 95.9600, Valid Loss: 0.2676\n",
      "Done\n",
      "Epoch [1/20], Loss: 0.3594\n",
      "Epoch [1/20], Valid Accuracy: 93.6200, Valid Loss: 0.2376\n",
      "Epoch [2/20], Loss: 0.2285\n",
      "Epoch [2/20], Valid Accuracy: 93.4800, Valid Loss: 0.2801\n",
      "Epoch [3/20], Loss: 0.2062\n",
      "Epoch [3/20], Valid Accuracy: 94.0000, Valid Loss: 0.2265\n",
      "Epoch [4/20], Loss: 0.1936\n",
      "Epoch [4/20], Valid Accuracy: 95.3000, Valid Loss: 0.1985\n",
      "Epoch [5/20], Loss: 0.1764\n",
      "Epoch [5/20], Valid Accuracy: 94.7600, Valid Loss: 0.2146\n",
      "Epoch [6/20], Loss: 0.1777\n",
      "Epoch [6/20], Valid Accuracy: 95.5300, Valid Loss: 0.1862\n",
      "Epoch [7/20], Loss: 0.1554\n",
      "Epoch [7/20], Valid Accuracy: 95.6600, Valid Loss: 0.1750\n",
      "Epoch [8/20], Loss: 0.1570\n",
      "Epoch [8/20], Valid Accuracy: 95.8700, Valid Loss: 0.2084\n",
      "Epoch [9/20], Loss: 0.1530\n",
      "Epoch [9/20], Valid Accuracy: 95.3700, Valid Loss: 0.2076\n",
      "Epoch [10/20], Loss: 0.1485\n",
      "Epoch [10/20], Valid Accuracy: 95.1500, Valid Loss: 0.2095\n",
      "Epoch [11/20], Loss: 0.1463\n",
      "Epoch [11/20], Valid Accuracy: 95.5100, Valid Loss: 0.2046\n",
      "Epoch [12/20], Loss: 0.1460\n",
      "Epoch [12/20], Valid Accuracy: 95.2700, Valid Loss: 0.2176\n",
      "Epoch [13/20], Loss: 0.1370\n",
      "Epoch [13/20], Valid Accuracy: 95.6200, Valid Loss: 0.2106\n",
      "Epoch [14/20], Loss: 0.1378\n",
      "Epoch [14/20], Valid Accuracy: 95.7000, Valid Loss: 0.1997\n",
      "Epoch [15/20], Loss: 0.1378\n",
      "Epoch [15/20], Valid Accuracy: 95.8000, Valid Loss: 0.2030\n",
      "Epoch [16/20], Loss: 0.1279\n",
      "Epoch [16/20], Valid Accuracy: 95.3100, Valid Loss: 0.3161\n",
      "Epoch [17/20], Loss: 0.1303\n",
      "Epoch [17/20], Valid Accuracy: 95.6200, Valid Loss: 0.2205\n",
      "Epoch [18/20], Loss: 0.1356\n",
      "Epoch [18/20], Valid Accuracy: 95.7000, Valid Loss: 0.2598\n",
      "Epoch [19/20], Loss: 0.1336\n",
      "Epoch [19/20], Valid Accuracy: 95.9000, Valid Loss: 0.2065\n",
      "Epoch [20/20], Loss: 0.1217\n",
      "Epoch [20/20], Valid Accuracy: 96.1200, Valid Loss: 0.2043\n",
      "Done\n",
      "Epoch [1/20], Loss: 0.2900\n",
      "Epoch [1/20], Valid Accuracy: 93.9900, Valid Loss: 0.2199\n",
      "Epoch [2/20], Loss: 0.1913\n",
      "Epoch [2/20], Valid Accuracy: 94.2800, Valid Loss: 0.2145\n",
      "Epoch [3/20], Loss: 0.1702\n",
      "Epoch [3/20], Valid Accuracy: 95.9600, Valid Loss: 0.1731\n",
      "Epoch [4/20], Loss: 0.1625\n",
      "Epoch [4/20], Valid Accuracy: 94.3100, Valid Loss: 0.2500\n",
      "Epoch [5/20], Loss: 0.1455\n",
      "Epoch [5/20], Valid Accuracy: 96.0900, Valid Loss: 0.1872\n",
      "Epoch [6/20], Loss: 0.1319\n",
      "Epoch [6/20], Valid Accuracy: 96.0700, Valid Loss: 0.2004\n",
      "Epoch [7/20], Loss: 0.1362\n",
      "Epoch [7/20], Valid Accuracy: 95.9500, Valid Loss: 0.2120\n",
      "Epoch [8/20], Loss: 0.1225\n",
      "Epoch [8/20], Valid Accuracy: 96.0500, Valid Loss: 0.1957\n",
      "Epoch [9/20], Loss: 0.1197\n",
      "Epoch [9/20], Valid Accuracy: 96.6500, Valid Loss: 0.1771\n",
      "Epoch [10/20], Loss: 0.1246\n",
      "Epoch [10/20], Valid Accuracy: 95.9200, Valid Loss: 0.1887\n",
      "Epoch [11/20], Loss: 0.1109\n",
      "Epoch [11/20], Valid Accuracy: 96.4700, Valid Loss: 0.1797\n",
      "Epoch [12/20], Loss: 0.1137\n",
      "Epoch [12/20], Valid Accuracy: 95.3700, Valid Loss: 0.2068\n",
      "Epoch [13/20], Loss: 0.1162\n",
      "Epoch [13/20], Valid Accuracy: 95.8700, Valid Loss: 0.2162\n",
      "Epoch [14/20], Loss: 0.1197\n",
      "Epoch [14/20], Valid Accuracy: 95.5800, Valid Loss: 0.2675\n",
      "Epoch [15/20], Loss: 0.1065\n",
      "Epoch [15/20], Valid Accuracy: 95.7300, Valid Loss: 0.2631\n",
      "Epoch [16/20], Loss: 0.1096\n",
      "Epoch [16/20], Valid Accuracy: 96.4000, Valid Loss: 0.1858\n",
      "Epoch [17/20], Loss: 0.1109\n",
      "Epoch [17/20], Valid Accuracy: 96.0600, Valid Loss: 0.2438\n",
      "Epoch [18/20], Loss: 0.1052\n",
      "Epoch [18/20], Valid Accuracy: 96.1000, Valid Loss: 0.2640\n",
      "Epoch [19/20], Loss: 0.1014\n",
      "Epoch [19/20], Valid Accuracy: 95.6400, Valid Loss: 0.2471\n",
      "Epoch [20/20], Loss: 0.1024\n",
      "Epoch [20/20], Valid Accuracy: 96.4800, Valid Loss: 0.1829\n",
      "Done\n",
      "Epoch [1/20], Loss: 0.2987\n",
      "Epoch [1/20], Valid Accuracy: 93.9100, Valid Loss: 0.2105\n",
      "Epoch [2/20], Loss: 0.2015\n",
      "Epoch [2/20], Valid Accuracy: 94.5000, Valid Loss: 0.2201\n",
      "Epoch [3/20], Loss: 0.1767\n",
      "Epoch [3/20], Valid Accuracy: 94.3700, Valid Loss: 0.2325\n",
      "Epoch [4/20], Loss: 0.1685\n",
      "Epoch [4/20], Valid Accuracy: 95.8700, Valid Loss: 0.1705\n",
      "Epoch [5/20], Loss: 0.1608\n",
      "Epoch [5/20], Valid Accuracy: 96.3500, Valid Loss: 0.1739\n",
      "Epoch [6/20], Loss: 0.1579\n",
      "Epoch [6/20], Valid Accuracy: 95.7900, Valid Loss: 0.1842\n",
      "Epoch [7/20], Loss: 0.1481\n",
      "Epoch [7/20], Valid Accuracy: 96.0800, Valid Loss: 0.2006\n",
      "Epoch [8/20], Loss: 0.1349\n",
      "Epoch [8/20], Valid Accuracy: 96.1800, Valid Loss: 0.1976\n",
      "Epoch [9/20], Loss: 0.1306\n",
      "Epoch [9/20], Valid Accuracy: 95.6200, Valid Loss: 0.2051\n",
      "Epoch [10/20], Loss: 0.1275\n",
      "Epoch [10/20], Valid Accuracy: 96.5800, Valid Loss: 0.1759\n",
      "Epoch [11/20], Loss: 0.1254\n",
      "Epoch [11/20], Valid Accuracy: 96.2600, Valid Loss: 0.1805\n",
      "Epoch [12/20], Loss: 0.1181\n",
      "Epoch [12/20], Valid Accuracy: 96.1000, Valid Loss: 0.2506\n",
      "Epoch [13/20], Loss: 0.1157\n",
      "Epoch [13/20], Valid Accuracy: 96.0900, Valid Loss: 0.2285\n",
      "Epoch [14/20], Loss: 0.1227\n",
      "Epoch [14/20], Valid Accuracy: 95.5800, Valid Loss: 0.2091\n",
      "Epoch [15/20], Loss: 0.1161\n",
      "Epoch [15/20], Valid Accuracy: 96.4000, Valid Loss: 0.2283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Loss: 0.1096\n",
      "Epoch [16/20], Valid Accuracy: 95.8300, Valid Loss: 0.2299\n",
      "Epoch [17/20], Loss: 0.1013\n",
      "Epoch [17/20], Valid Accuracy: 96.7800, Valid Loss: 0.1889\n",
      "Epoch [18/20], Loss: 0.1063\n",
      "Epoch [18/20], Valid Accuracy: 96.0600, Valid Loss: 0.2572\n",
      "Epoch [19/20], Loss: 0.1085\n",
      "Epoch [19/20], Valid Accuracy: 96.4300, Valid Loss: 0.2351\n",
      "Epoch [20/20], Loss: 0.0981\n",
      "Epoch [20/20], Valid Accuracy: 96.2100, Valid Loss: 0.2636\n",
      "Done\n",
      "Epoch [1/20], Loss: 0.3501\n",
      "Epoch [1/20], Valid Accuracy: 93.6700, Valid Loss: 0.2195\n",
      "Epoch [2/20], Loss: 0.2351\n",
      "Epoch [2/20], Valid Accuracy: 93.8300, Valid Loss: 0.2413\n",
      "Epoch [3/20], Loss: 0.2023\n",
      "Epoch [3/20], Valid Accuracy: 94.7500, Valid Loss: 0.2006\n",
      "Epoch [4/20], Loss: 0.1888\n",
      "Epoch [4/20], Valid Accuracy: 94.8200, Valid Loss: 0.2059\n",
      "Epoch [5/20], Loss: 0.1723\n",
      "Epoch [5/20], Valid Accuracy: 94.0100, Valid Loss: 0.2509\n",
      "Epoch [6/20], Loss: 0.1676\n",
      "Epoch [6/20], Valid Accuracy: 95.2000, Valid Loss: 0.2278\n",
      "Epoch [7/20], Loss: 0.1639\n",
      "Epoch [7/20], Valid Accuracy: 95.8200, Valid Loss: 0.1919\n",
      "Epoch [8/20], Loss: 0.1547\n",
      "Epoch [8/20], Valid Accuracy: 95.8000, Valid Loss: 0.1844\n",
      "Epoch [9/20], Loss: 0.1581\n",
      "Epoch [9/20], Valid Accuracy: 94.9100, Valid Loss: 0.2444\n",
      "Epoch [10/20], Loss: 0.1511\n",
      "Epoch [10/20], Valid Accuracy: 95.7800, Valid Loss: 0.1912\n",
      "Epoch [11/20], Loss: 0.1430\n",
      "Epoch [11/20], Valid Accuracy: 95.1400, Valid Loss: 0.2207\n",
      "Epoch [12/20], Loss: 0.1394\n",
      "Epoch [12/20], Valid Accuracy: 95.5500, Valid Loss: 0.2344\n",
      "Epoch [13/20], Loss: 0.1350\n",
      "Epoch [13/20], Valid Accuracy: 95.8500, Valid Loss: 0.1945\n",
      "Epoch [14/20], Loss: 0.1350\n",
      "Epoch [14/20], Valid Accuracy: 95.7800, Valid Loss: 0.2102\n",
      "Epoch [15/20], Loss: 0.1333\n",
      "Epoch [15/20], Valid Accuracy: 96.0000, Valid Loss: 0.2178\n",
      "Epoch [16/20], Loss: 0.1405\n",
      "Epoch [16/20], Valid Accuracy: 95.5700, Valid Loss: 0.2276\n",
      "Epoch [17/20], Loss: 0.1354\n",
      "Epoch [17/20], Valid Accuracy: 95.9300, Valid Loss: 0.2135\n",
      "Epoch [18/20], Loss: 0.1264\n",
      "Epoch [18/20], Valid Accuracy: 95.9200, Valid Loss: 0.1983\n",
      "Epoch [19/20], Loss: 0.1229\n",
      "Epoch [19/20], Valid Accuracy: 95.3400, Valid Loss: 0.2586\n",
      "Epoch [20/20], Loss: 0.1268\n",
      "Epoch [20/20], Valid Accuracy: 96.0000, Valid Loss: 0.1998\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "lr=0.01\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "valid_acc  = []\n",
    "for k in p:\n",
    "    net = get_model_v2(M=[k['M1'],k['M2']],p=[0,0])\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "    _,_ ,trn_loss=train_model(train_loader, test_loader, num_epochs=20, model=net, optimizer=optimizer)\n",
    "    vld_acc,val_loss=model_accuracy_loss(net, test_loader)\n",
    "    valid_loss.append(val_loss)\n",
    "    train_loss.append(trn_loss)\n",
    "    valid_acc.append(vld_acc)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = pd.DataFrame(p)\n",
    "p['valid_acc']  = valid_acc\n",
    "p['train_loss'] = train_loss\n",
    "p['valid_loss'] = valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M1</th>\n",
       "      <th>M2</th>\n",
       "      <th>valid_acc</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300</td>\n",
       "      <td>100</td>\n",
       "      <td>96.63</td>\n",
       "      <td>0.105879</td>\n",
       "      <td>0.219713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300</td>\n",
       "      <td>150</td>\n",
       "      <td>95.96</td>\n",
       "      <td>0.107845</td>\n",
       "      <td>0.267601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>500</td>\n",
       "      <td>96.12</td>\n",
       "      <td>0.121723</td>\n",
       "      <td>0.204303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>96.48</td>\n",
       "      <td>0.102442</td>\n",
       "      <td>0.182949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500</td>\n",
       "      <td>150</td>\n",
       "      <td>96.21</td>\n",
       "      <td>0.098060</td>\n",
       "      <td>0.263609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>96.00</td>\n",
       "      <td>0.126830</td>\n",
       "      <td>0.199787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    M1   M2  valid_acc  train_loss  valid_loss\n",
       "0  300  100      96.63    0.105879    0.219713\n",
       "1  300  150      95.96    0.107845    0.267601\n",
       "2  300  500      96.12    0.121723    0.204303\n",
       "3  500  100      96.48    0.102442    0.182949\n",
       "4  500  150      96.21    0.098060    0.263609\n",
       "5  500  500      96.00    0.126830    0.199787"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above experiments, it can be seen that validation accuracy is maximum for M1=300 and M2 =150`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1481.8435\n",
      "Epoch [1/10], Valid Accuracy: 9.9300, Valid Loss: 17.2778\n",
      "Epoch [2/10], Loss: 27.2117\n",
      "Epoch [2/10], Valid Accuracy: 10.2700, Valid Loss: 18.8791\n",
      "Epoch [3/10], Loss: 2.3624\n",
      "Epoch [3/10], Valid Accuracy: 9.9900, Valid Loss: 18.9502\n",
      "Epoch [4/10], Loss: 2.3671\n",
      "Epoch [4/10], Valid Accuracy: 11.5300, Valid Loss: 18.8894\n",
      "Epoch [5/10], Loss: 2.3630\n",
      "Epoch [5/10], Valid Accuracy: 10.5000, Valid Loss: 18.8971\n",
      "Epoch [6/10], Loss: 2.3694\n",
      "Epoch [6/10], Valid Accuracy: 9.7800, Valid Loss: 18.8947\n",
      "Epoch [7/10], Loss: 2.3646\n",
      "Epoch [7/10], Valid Accuracy: 10.5000, Valid Loss: 18.9454\n",
      "Epoch [8/10], Loss: 2.3697\n",
      "Epoch [8/10], Valid Accuracy: 9.7500, Valid Loss: 18.8741\n",
      "Epoch [9/10], Loss: 2.3671\n",
      "Epoch [9/10], Valid Accuracy: 10.5000, Valid Loss: 18.9361\n",
      "Epoch [10/10], Loss: 2.3647\n",
      "Epoch [10/10], Valid Accuracy: 11.5300, Valid Loss: 18.8769\n",
      "Epoch [1/10], Loss: 3.2400\n",
      "Epoch [1/10], Valid Accuracy: 28.4900, Valid Loss: 1.8562\n",
      "Epoch [2/10], Loss: 1.9188\n",
      "Epoch [2/10], Valid Accuracy: 29.1600, Valid Loss: 1.7087\n",
      "Epoch [3/10], Loss: 1.9083\n",
      "Epoch [3/10], Valid Accuracy: 30.1300, Valid Loss: 1.7085\n",
      "Epoch [4/10], Loss: 1.8141\n",
      "Epoch [4/10], Valid Accuracy: 28.1900, Valid Loss: 1.7051\n",
      "Epoch [5/10], Loss: 1.7663\n",
      "Epoch [5/10], Valid Accuracy: 27.1200, Valid Loss: 1.7272\n",
      "Epoch [6/10], Loss: 1.9776\n",
      "Epoch [6/10], Valid Accuracy: 17.3600, Valid Loss: 1.9875\n",
      "Epoch [7/10], Loss: 2.0288\n",
      "Epoch [7/10], Valid Accuracy: 20.1900, Valid Loss: 2.0795\n",
      "Epoch [8/10], Loss: 2.1105\n",
      "Epoch [8/10], Valid Accuracy: 21.0200, Valid Loss: 2.0495\n",
      "Epoch [9/10], Loss: 2.0674\n",
      "Epoch [9/10], Valid Accuracy: 20.6500, Valid Loss: 2.0453\n",
      "Epoch [10/10], Loss: 2.0583\n",
      "Epoch [10/10], Valid Accuracy: 17.9000, Valid Loss: 2.0275\n",
      "Epoch [1/10], Loss: 0.2869\n",
      "Epoch [1/10], Valid Accuracy: 94.3900, Valid Loss: 0.2189\n",
      "Epoch [2/10], Loss: 0.1969\n",
      "Epoch [2/10], Valid Accuracy: 95.8200, Valid Loss: 0.1931\n",
      "Epoch [3/10], Loss: 0.1713\n",
      "Epoch [3/10], Valid Accuracy: 95.5500, Valid Loss: 0.1720\n",
      "Epoch [4/10], Loss: 0.1516\n",
      "Epoch [4/10], Valid Accuracy: 95.1300, Valid Loss: 0.2066\n",
      "Epoch [5/10], Loss: 0.1483\n",
      "Epoch [5/10], Valid Accuracy: 95.7300, Valid Loss: 0.1963\n",
      "Epoch [6/10], Loss: 0.1363\n",
      "Epoch [6/10], Valid Accuracy: 96.0100, Valid Loss: 0.1798\n",
      "Epoch [7/10], Loss: 0.1419\n",
      "Epoch [7/10], Valid Accuracy: 95.9100, Valid Loss: 0.1997\n",
      "Epoch [8/10], Loss: 0.1299\n",
      "Epoch [8/10], Valid Accuracy: 95.3100, Valid Loss: 0.2294\n",
      "Epoch [9/10], Loss: 0.1237\n",
      "Epoch [9/10], Valid Accuracy: 95.8700, Valid Loss: 0.1993\n",
      "Epoch [10/10], Loss: 0.1263\n",
      "Epoch [10/10], Valid Accuracy: 95.0900, Valid Loss: 0.2490\n",
      "Epoch [1/10], Loss: 0.2284\n",
      "Epoch [1/10], Valid Accuracy: 96.5900, Valid Loss: 0.1080\n",
      "Epoch [2/10], Loss: 0.0923\n",
      "Epoch [2/10], Valid Accuracy: 96.9200, Valid Loss: 0.0972\n",
      "Epoch [3/10], Loss: 0.0646\n",
      "Epoch [3/10], Valid Accuracy: 97.3600, Valid Loss: 0.0797\n",
      "Epoch [4/10], Loss: 0.0482\n",
      "Epoch [4/10], Valid Accuracy: 97.5300, Valid Loss: 0.0860\n",
      "Epoch [5/10], Loss: 0.0382\n",
      "Epoch [5/10], Valid Accuracy: 97.8400, Valid Loss: 0.0779\n",
      "Epoch [6/10], Loss: 0.0315\n",
      "Epoch [6/10], Valid Accuracy: 97.8900, Valid Loss: 0.0776\n",
      "Epoch [7/10], Loss: 0.0287\n",
      "Epoch [7/10], Valid Accuracy: 97.3100, Valid Loss: 0.1004\n",
      "Epoch [8/10], Loss: 0.0241\n",
      "Epoch [8/10], Valid Accuracy: 98.0300, Valid Loss: 0.0768\n",
      "Epoch [9/10], Loss: 0.0237\n",
      "Epoch [9/10], Valid Accuracy: 98.0900, Valid Loss: 0.0800\n",
      "Epoch [10/10], Loss: 0.0170\n",
      "Epoch [10/10], Valid Accuracy: 98.0700, Valid Loss: 0.0848\n",
      "Epoch [1/10], Loss: 0.5018\n",
      "Epoch [1/10], Valid Accuracy: 92.9000, Valid Loss: 0.2466\n",
      "Epoch [2/10], Loss: 0.2190\n",
      "Epoch [2/10], Valid Accuracy: 94.7200, Valid Loss: 0.1815\n",
      "Epoch [3/10], Loss: 0.1649\n",
      "Epoch [3/10], Valid Accuracy: 95.7400, Valid Loss: 0.1458\n",
      "Epoch [4/10], Loss: 0.1316\n",
      "Epoch [4/10], Valid Accuracy: 96.2600, Valid Loss: 0.1261\n",
      "Epoch [5/10], Loss: 0.1083\n",
      "Epoch [5/10], Valid Accuracy: 96.7600, Valid Loss: 0.1061\n",
      "Epoch [6/10], Loss: 0.0898\n",
      "Epoch [6/10], Valid Accuracy: 97.2000, Valid Loss: 0.0969\n",
      "Epoch [7/10], Loss: 0.0762\n",
      "Epoch [7/10], Valid Accuracy: 97.1600, Valid Loss: 0.0963\n",
      "Epoch [8/10], Loss: 0.0657\n",
      "Epoch [8/10], Valid Accuracy: 97.4700, Valid Loss: 0.0835\n",
      "Epoch [9/10], Loss: 0.0562\n",
      "Epoch [9/10], Valid Accuracy: 97.5400, Valid Loss: 0.0797\n",
      "Epoch [10/10], Loss: 0.0493\n",
      "Epoch [10/10], Valid Accuracy: 97.7800, Valid Loss: 0.0727\n",
      "Epoch [1/10], Loss: 1.5367\n",
      "Epoch [1/10], Valid Accuracy: 84.8500, Valid Loss: 0.8131\n",
      "Epoch [2/10], Loss: 0.6201\n",
      "Epoch [2/10], Valid Accuracy: 88.8800, Valid Loss: 0.4740\n",
      "Epoch [3/10], Loss: 0.4369\n",
      "Epoch [3/10], Valid Accuracy: 90.2200, Valid Loss: 0.3803\n",
      "Epoch [4/10], Loss: 0.3708\n",
      "Epoch [4/10], Valid Accuracy: 90.8100, Valid Loss: 0.3374\n",
      "Epoch [5/10], Loss: 0.3358\n",
      "Epoch [5/10], Valid Accuracy: 91.2800, Valid Loss: 0.3109\n",
      "Epoch [6/10], Loss: 0.3127\n",
      "Epoch [6/10], Valid Accuracy: 91.6900, Valid Loss: 0.2928\n",
      "Epoch [7/10], Loss: 0.2959\n",
      "Epoch [7/10], Valid Accuracy: 92.0100, Valid Loss: 0.2800\n",
      "Epoch [8/10], Loss: 0.2822\n",
      "Epoch [8/10], Valid Accuracy: 92.2900, Valid Loss: 0.2676\n",
      "Epoch [9/10], Loss: 0.2705\n",
      "Epoch [9/10], Valid Accuracy: 92.5300, Valid Loss: 0.2579\n",
      "Epoch [10/10], Loss: 0.2601\n",
      "Epoch [10/10], Valid Accuracy: 92.8400, Valid Loss: 0.2500\n"
     ]
    }
   ],
   "source": [
    "valid_acc = []\n",
    "lr = [1, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "for l in lr:\n",
    "    net = get_model_v2(M=[300,100],p=[0,0])\n",
    "    optimizer = optim.Adam(net.parameters(), lr=l)\n",
    "    train_model(train_loader, test_loader, num_epochs=10, model=net, optimizer=optimizer)\n",
    "    vld_acc,_= model_accuracy_loss(net, test_loader)\n",
    "    valid_acc.append(vld_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fabe1aad2e8>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fabe1b389b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lr,valid_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>vld_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>11.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.10000</td>\n",
       "      <td>17.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>92.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01000</td>\n",
       "      <td>95.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>97.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00100</td>\n",
       "      <td>98.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lr  vld_acc\n",
       "0  1.00000    11.53\n",
       "1  0.10000    17.90\n",
       "5  0.00001    92.84\n",
       "2  0.01000    95.09\n",
       "4  0.00010    97.78\n",
       "3  0.00100    98.07"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'lr':lr,\n",
    "             'vld_acc': valid_acc}).sort_values(by='vld_acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning rate with maximum validation accuracy is  0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'p1':[0, 0.2, 0.4, 0.5],\n",
    "              'p2':[0, 0.2, 0.4, 0.5]\n",
    "             }\n",
    "p = list(ParameterGrid(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.2278\n",
      "Epoch [1/10], Valid Accuracy: 96.6800, Valid Loss: 0.1078\n",
      "Epoch [2/10], Loss: 0.0923\n",
      "Epoch [2/10], Valid Accuracy: 97.2600, Valid Loss: 0.0898\n",
      "Epoch [3/10], Loss: 0.0654\n",
      "Epoch [3/10], Valid Accuracy: 97.6800, Valid Loss: 0.0762\n",
      "Epoch [4/10], Loss: 0.0486\n",
      "Epoch [4/10], Valid Accuracy: 97.4400, Valid Loss: 0.0847\n",
      "Epoch [5/10], Loss: 0.0403\n",
      "Epoch [5/10], Valid Accuracy: 97.5900, Valid Loss: 0.0853\n",
      "Epoch [6/10], Loss: 0.0331\n",
      "Epoch [6/10], Valid Accuracy: 97.9800, Valid Loss: 0.0762\n",
      "Epoch [7/10], Loss: 0.0262\n",
      "Epoch [7/10], Valid Accuracy: 97.9200, Valid Loss: 0.0800\n",
      "Epoch [8/10], Loss: 0.0265\n",
      "Epoch [8/10], Valid Accuracy: 97.5400, Valid Loss: 0.1004\n",
      "Epoch [9/10], Loss: 0.0227\n",
      "Epoch [9/10], Valid Accuracy: 97.9400, Valid Loss: 0.0803\n",
      "Epoch [10/10], Loss: 0.0196\n",
      "Epoch [10/10], Valid Accuracy: 97.7600, Valid Loss: 0.0902\n",
      "Done\n",
      "Epoch [1/10], Loss: 0.2509\n",
      "Epoch [1/10], Valid Accuracy: 96.5400, Valid Loss: 0.1158\n",
      "Epoch [2/10], Loss: 0.1047\n",
      "Epoch [2/10], Valid Accuracy: 97.4000, Valid Loss: 0.0816\n",
      "Epoch [3/10], Loss: 0.0742\n",
      "Epoch [3/10], Valid Accuracy: 97.5000, Valid Loss: 0.0762\n",
      "Epoch [4/10], Loss: 0.0577\n",
      "Epoch [4/10], Valid Accuracy: 97.6900, Valid Loss: 0.0767\n",
      "Epoch [5/10], Loss: 0.0457\n",
      "Epoch [5/10], Valid Accuracy: 97.4900, Valid Loss: 0.0905\n",
      "Epoch [6/10], Loss: 0.0406\n",
      "Epoch [6/10], Valid Accuracy: 97.6000, Valid Loss: 0.0837\n",
      "Epoch [7/10], Loss: 0.0345\n",
      "Epoch [7/10], Valid Accuracy: 98.0000, Valid Loss: 0.0739\n",
      "Epoch [8/10], Loss: 0.0301\n",
      "Epoch [8/10], Valid Accuracy: 98.0200, Valid Loss: 0.0702\n",
      "Epoch [9/10], Loss: 0.0258\n",
      "Epoch [9/10], Valid Accuracy: 98.2900, Valid Loss: 0.0733\n",
      "Epoch [10/10], Loss: 0.0258\n",
      "Epoch [10/10], Valid Accuracy: 97.8700, Valid Loss: 0.0886\n",
      "Done\n",
      "Epoch [1/10], Loss: 0.2793\n",
      "Epoch [1/10], Valid Accuracy: 95.8700, Valid Loss: 0.1287\n",
      "Epoch [2/10], Loss: 0.1184\n",
      "Epoch [2/10], Valid Accuracy: 97.0500, Valid Loss: 0.0897\n",
      "Epoch [3/10], Loss: 0.0874\n",
      "Epoch [3/10], Valid Accuracy: 97.5200, Valid Loss: 0.0812\n",
      "Epoch [4/10], Loss: 0.0682\n",
      "Epoch [4/10], Valid Accuracy: 97.6700, Valid Loss: 0.0774\n",
      "Epoch [5/10], Loss: 0.0570\n",
      "Epoch [5/10], Valid Accuracy: 97.6100, Valid Loss: 0.0862\n",
      "Epoch [6/10], Loss: 0.0492\n",
      "Epoch [6/10], Valid Accuracy: 97.9000, Valid Loss: 0.0762\n",
      "Epoch [7/10], Loss: 0.0425\n",
      "Epoch [7/10], Valid Accuracy: 97.9100, Valid Loss: 0.0799\n",
      "Epoch [8/10], Loss: 0.0402\n",
      "Epoch [8/10], Valid Accuracy: 97.9900, Valid Loss: 0.0754\n",
      "Epoch [9/10], Loss: 0.0343\n",
      "Epoch [9/10], Valid Accuracy: 97.8400, Valid Loss: 0.0836\n",
      "Epoch [10/10], Loss: 0.0293\n",
      "Epoch [10/10], Valid Accuracy: 98.0000, Valid Loss: 0.0818\n",
      "Done\n",
      "Epoch [1/10], Loss: 0.3080\n",
      "Epoch [1/10], Valid Accuracy: 96.1900, Valid Loss: 0.1228\n",
      "Epoch [2/10], Loss: 0.1333\n",
      "Epoch [2/10], Valid Accuracy: 96.7300, Valid Loss: 0.1006\n",
      "Epoch [3/10], Loss: 0.0959\n",
      "Epoch [3/10], Valid Accuracy: 97.2300, Valid Loss: 0.0869\n",
      "Epoch [4/10], Loss: 0.0769\n",
      "Epoch [4/10], Valid Accuracy: 97.7300, Valid Loss: 0.0800\n",
      "Epoch [5/10], Loss: 0.0661\n",
      "Epoch [5/10], Valid Accuracy: 97.8000, Valid Loss: 0.0730\n",
      "Epoch [6/10], Loss: 0.0563\n",
      "Epoch [6/10], Valid Accuracy: 97.9600, Valid Loss: 0.0761\n",
      "Epoch [7/10], Loss: 0.0476\n",
      "Epoch [7/10], Valid Accuracy: 97.6400, Valid Loss: 0.0862\n",
      "Epoch [8/10], Loss: 0.0428\n",
      "Epoch [8/10], Valid Accuracy: 97.6300, Valid Loss: 0.0875\n",
      "Epoch [9/10], Loss: 0.0411\n",
      "Epoch [9/10], Valid Accuracy: 97.7600, Valid Loss: 0.0925\n",
      "Epoch [10/10], Loss: 0.0364\n",
      "Epoch [10/10], Valid Accuracy: 97.8900, Valid Loss: 0.0960\n",
      "Done\n",
      "Epoch [1/10], Loss: 0.2508\n",
      "Epoch [1/10], Valid Accuracy: 95.8000, Valid Loss: 0.1304\n",
      "Epoch [2/10], Loss: 0.1164\n",
      "Epoch [2/10], Valid Accuracy: 96.6300, Valid Loss: 0.1020\n",
      "Epoch [3/10], Loss: 0.0893\n",
      "Epoch [3/10], Valid Accuracy: 97.5300, Valid Loss: 0.0794\n",
      "Epoch [4/10], Loss: 0.0712\n",
      "Epoch [4/10], Valid Accuracy: 97.7500, Valid Loss: 0.0730\n",
      "Epoch [5/10], Loss: 0.0641\n",
      "Epoch [5/10], Valid Accuracy: 97.5200, Valid Loss: 0.0829\n",
      "Epoch [6/10], Loss: 0.0523\n",
      "Epoch [6/10], Valid Accuracy: 97.7800, Valid Loss: 0.0753\n",
      "Epoch [7/10], Loss: 0.0508\n",
      "Epoch [7/10], Valid Accuracy: 97.9800, Valid Loss: 0.0696\n",
      "Epoch [8/10], Loss: 0.0454\n",
      "Epoch [8/10], Valid Accuracy: 97.8000, Valid Loss: 0.0733\n",
      "Epoch [9/10], Loss: 0.0406\n",
      "Epoch [9/10], Valid Accuracy: 98.0700, Valid Loss: 0.0692\n",
      "Epoch [10/10], Loss: 0.0378\n",
      "Epoch [10/10], Valid Accuracy: 98.2800, Valid Loss: 0.0656\n",
      "Done\n",
      "Epoch [1/10], Loss: 0.2803\n",
      "Epoch [1/10], Valid Accuracy: 96.4000, Valid Loss: 0.1183\n",
      "Epoch [2/10], Loss: 0.1279\n",
      "Epoch [2/10], Valid Accuracy: 97.0700, Valid Loss: 0.0938\n",
      "Epoch [3/10], Loss: 0.0999\n",
      "Epoch [3/10], Valid Accuracy: 97.5300, Valid Loss: 0.0779\n",
      "Epoch [4/10], Loss: 0.0828\n",
      "Epoch [4/10], Valid Accuracy: 97.7100, Valid Loss: 0.0715\n",
      "Epoch [5/10], Loss: 0.0688\n",
      "Epoch [5/10], Valid Accuracy: 97.6300, Valid Loss: 0.0781\n",
      "Epoch [6/10], Loss: 0.0640\n",
      "Epoch [6/10], Valid Accuracy: 97.7700, Valid Loss: 0.0720\n",
      "Epoch [7/10], Loss: 0.0561\n",
      "Epoch [7/10], Valid Accuracy: 97.8300, Valid Loss: 0.0706\n",
      "Epoch [8/10], Loss: 0.0531\n",
      "Epoch [8/10], Valid Accuracy: 97.9300, Valid Loss: 0.0783\n",
      "Epoch [9/10], Loss: 0.0479\n",
      "Epoch [9/10], Valid Accuracy: 98.2600, Valid Loss: 0.0680\n",
      "Epoch [10/10], Loss: 0.0458\n",
      "Epoch [10/10], Valid Accuracy: 97.8800, Valid Loss: 0.0748\n",
      "Done\n",
      "Epoch [1/10], Loss: 0.3178\n",
      "Epoch [1/10], Valid Accuracy: 96.0500, Valid Loss: 0.1250\n",
      "Epoch [2/10], Loss: 0.1456\n",
      "Epoch [2/10], Valid Accuracy: 97.3700, Valid Loss: 0.0917\n",
      "Epoch [3/10], Loss: 0.1133\n",
      "Epoch [3/10], Valid Accuracy: 97.5300, Valid Loss: 0.0857\n",
      "Epoch [4/10], Loss: 0.0967\n",
      "Epoch [4/10], Valid Accuracy: 97.5400, Valid Loss: 0.0815\n",
      "Epoch [5/10], Loss: 0.0840\n",
      "Epoch [5/10], Valid Accuracy: 97.6100, Valid Loss: 0.0802\n",
      "Epoch [6/10], Loss: 0.0779\n",
      "Epoch [6/10], Valid Accuracy: 97.6900, Valid Loss: 0.0769\n",
      "Epoch [7/10], Loss: 0.0696\n",
      "Epoch [7/10], Valid Accuracy: 98.0200, Valid Loss: 0.0758\n",
      "Epoch [8/10], Loss: 0.0652\n",
      "Epoch [8/10], Valid Accuracy: 97.7700, Valid Loss: 0.0776\n",
      "Epoch [9/10], Loss: 0.0581\n",
      "Epoch [9/10], Valid Accuracy: 97.8900, Valid Loss: 0.0757\n",
      "Epoch [10/10], Loss: 0.0553\n",
      "Epoch [10/10], Valid Accuracy: 97.9600, Valid Loss: 0.0794\n",
      "Done\n",
      "Epoch [1/10], Loss: 0.3420\n",
      "Epoch [1/10], Valid Accuracy: 96.1200, Valid Loss: 0.1231\n",
      "Epoch [2/10], Loss: 0.1624\n",
      "Epoch [2/10], Valid Accuracy: 96.7700, Valid Loss: 0.1073\n",
      "Epoch [3/10], Loss: 0.1255\n",
      "Epoch [3/10], Valid Accuracy: 97.6800, Valid Loss: 0.0795\n",
      "Epoch [4/10], Loss: 0.1057\n",
      "Epoch [4/10], Valid Accuracy: 97.5600, Valid Loss: 0.0813\n",
      "Epoch [5/10], Loss: 0.0947\n",
      "Epoch [5/10], Valid Accuracy: 97.8700, Valid Loss: 0.0725\n",
      "Epoch [6/10], Loss: 0.0863\n",
      "Epoch [6/10], Valid Accuracy: 97.5800, Valid Loss: 0.0836\n",
      "Epoch [7/10], Loss: 0.0759\n",
      "Epoch [7/10], Valid Accuracy: 97.8000, Valid Loss: 0.0775\n",
      "Epoch [8/10], Loss: 0.0718\n",
      "Epoch [8/10], Valid Accuracy: 97.8400, Valid Loss: 0.0777\n",
      "Epoch [9/10], Loss: 0.0696\n",
      "Epoch [9/10], Valid Accuracy: 97.8800, Valid Loss: 0.0702\n",
      "Epoch [10/10], Loss: 0.0654\n",
      "Epoch [10/10], Valid Accuracy: 97.6900, Valid Loss: 0.0919\n",
      "Done\n",
      "Epoch [1/10], Loss: 0.2918\n",
      "Epoch [1/10], Valid Accuracy: 95.8500, Valid Loss: 0.1303\n",
      "Epoch [2/10], Loss: 0.1501\n",
      "Epoch [2/10], Valid Accuracy: 97.0100, Valid Loss: 0.0984\n",
      "Epoch [3/10], Loss: 0.1223\n",
      "Epoch [3/10], Valid Accuracy: 97.3400, Valid Loss: 0.0856\n",
      "Epoch [4/10], Loss: 0.1012\n",
      "Epoch [4/10], Valid Accuracy: 97.6900, Valid Loss: 0.0793\n",
      "Epoch [5/10], Loss: 0.0943\n",
      "Epoch [5/10], Valid Accuracy: 97.7200, Valid Loss: 0.0777\n",
      "Epoch [6/10], Loss: 0.0862\n",
      "Epoch [6/10], Valid Accuracy: 97.8800, Valid Loss: 0.0707\n",
      "Epoch [7/10], Loss: 0.0784\n",
      "Epoch [7/10], Valid Accuracy: 97.8600, Valid Loss: 0.0674\n",
      "Epoch [8/10], Loss: 0.0725\n",
      "Epoch [8/10], Valid Accuracy: 98.0900, Valid Loss: 0.0674\n",
      "Epoch [9/10], Loss: 0.0712\n",
      "Epoch [9/10], Valid Accuracy: 98.0900, Valid Loss: 0.0659\n",
      "Epoch [10/10], Loss: 0.0627\n",
      "Epoch [10/10], Valid Accuracy: 98.0800, Valid Loss: 0.0702\n",
      "Done\n",
      "Epoch [1/10], Loss: 0.3185\n",
      "Epoch [1/10], Valid Accuracy: 95.8800, Valid Loss: 0.1324\n",
      "Epoch [2/10], Loss: 0.1645\n",
      "Epoch [2/10], Valid Accuracy: 96.7900, Valid Loss: 0.1024\n",
      "Epoch [3/10], Loss: 0.1334\n",
      "Epoch [3/10], Valid Accuracy: 97.3700, Valid Loss: 0.0851\n",
      "Epoch [4/10], Loss: 0.1163\n",
      "Epoch [4/10], Valid Accuracy: 97.4700, Valid Loss: 0.0824\n",
      "Epoch [5/10], Loss: 0.1043\n",
      "Epoch [5/10], Valid Accuracy: 97.4000, Valid Loss: 0.0801\n",
      "Epoch [6/10], Loss: 0.0971\n",
      "Epoch [6/10], Valid Accuracy: 97.7200, Valid Loss: 0.0737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Loss: 0.0909\n",
      "Epoch [7/10], Valid Accuracy: 97.8500, Valid Loss: 0.0745\n",
      "Epoch [8/10], Loss: 0.0862\n",
      "Epoch [8/10], Valid Accuracy: 97.8300, Valid Loss: 0.0700\n",
      "Epoch [9/10], Loss: 0.0766\n",
      "Epoch [9/10], Valid Accuracy: 97.9600, Valid Loss: 0.0705\n",
      "Epoch [10/10], Loss: 0.0794\n",
      "Epoch [10/10], Valid Accuracy: 97.8700, Valid Loss: 0.0735\n",
      "Done\n",
      "Epoch [1/10], Loss: 0.3582\n",
      "Epoch [1/10], Valid Accuracy: 96.2400, Valid Loss: 0.1284\n",
      "Epoch [2/10], Loss: 0.1826\n",
      "Epoch [2/10], Valid Accuracy: 96.5800, Valid Loss: 0.1078\n",
      "Epoch [3/10], Loss: 0.1535\n",
      "Epoch [3/10], Valid Accuracy: 97.4100, Valid Loss: 0.0863\n",
      "Epoch [4/10], Loss: 0.1312\n",
      "Epoch [4/10], Valid Accuracy: 97.4700, Valid Loss: 0.0809\n",
      "Epoch [5/10], Loss: 0.1233\n",
      "Epoch [5/10], Valid Accuracy: 97.5600, Valid Loss: 0.0815\n",
      "Epoch [6/10], Loss: 0.1091\n",
      "Epoch [6/10], Valid Accuracy: 97.5700, Valid Loss: 0.0818\n",
      "Epoch [7/10], Loss: 0.1068\n",
      "Epoch [7/10], Valid Accuracy: 97.8000, Valid Loss: 0.0737\n",
      "Epoch [8/10], Loss: 0.0978\n",
      "Epoch [8/10], Valid Accuracy: 97.6400, Valid Loss: 0.0801\n",
      "Epoch [9/10], Loss: 0.0930\n",
      "Epoch [9/10], Valid Accuracy: 97.7400, Valid Loss: 0.0782\n",
      "Epoch [10/10], Loss: 0.0878\n",
      "Epoch [10/10], Valid Accuracy: 97.7600, Valid Loss: 0.0731\n",
      "Done\n",
      "Epoch [1/10], Loss: 0.3873\n",
      "Epoch [1/10], Valid Accuracy: 95.4300, Valid Loss: 0.1446\n",
      "Epoch [2/10], Loss: 0.1991\n",
      "Epoch [2/10], Valid Accuracy: 96.5200, Valid Loss: 0.1136\n",
      "Epoch [3/10], Loss: 0.1624\n",
      "Epoch [3/10], Valid Accuracy: 97.1800, Valid Loss: 0.0986\n",
      "Epoch [4/10], Loss: 0.1502\n",
      "Epoch [4/10], Valid Accuracy: 97.4000, Valid Loss: 0.0867\n",
      "Epoch [5/10], Loss: 0.1310\n",
      "Epoch [5/10], Valid Accuracy: 97.4800, Valid Loss: 0.0874\n",
      "Epoch [6/10], Loss: 0.1232\n",
      "Epoch [6/10], Valid Accuracy: 97.6000, Valid Loss: 0.0795\n",
      "Epoch [7/10], Loss: 0.1145\n",
      "Epoch [7/10], Valid Accuracy: 97.5200, Valid Loss: 0.0814\n",
      "Epoch [8/10], Loss: 0.1106\n",
      "Epoch [8/10], Valid Accuracy: 97.7400, Valid Loss: 0.0809\n",
      "Epoch [9/10], Loss: 0.1029\n",
      "Epoch [9/10], Valid Accuracy: 97.8500, Valid Loss: 0.0723\n",
      "Epoch [10/10], Loss: 0.0985\n",
      "Epoch [10/10], Valid Accuracy: 97.9700, Valid Loss: 0.0722\n",
      "Done\n",
      "Epoch [1/10], Loss: 0.3158\n",
      "Epoch [1/10], Valid Accuracy: 95.7200, Valid Loss: 0.1417\n",
      "Epoch [2/10], Loss: 0.1741\n",
      "Epoch [2/10], Valid Accuracy: 96.9400, Valid Loss: 0.1021\n",
      "Epoch [3/10], Loss: 0.1406\n",
      "Epoch [3/10], Valid Accuracy: 97.2800, Valid Loss: 0.0893\n",
      "Epoch [4/10], Loss: 0.1246\n",
      "Epoch [4/10], Valid Accuracy: 97.4000, Valid Loss: 0.0837\n",
      "Epoch [5/10], Loss: 0.1135\n",
      "Epoch [5/10], Valid Accuracy: 97.6900, Valid Loss: 0.0768\n",
      "Epoch [6/10], Loss: 0.1039\n",
      "Epoch [6/10], Valid Accuracy: 97.9800, Valid Loss: 0.0684\n",
      "Epoch [7/10], Loss: 0.0962\n",
      "Epoch [7/10], Valid Accuracy: 97.9600, Valid Loss: 0.0658\n",
      "Epoch [8/10], Loss: 0.0918\n",
      "Epoch [8/10], Valid Accuracy: 97.9400, Valid Loss: 0.0670\n",
      "Epoch [9/10], Loss: 0.0879\n",
      "Epoch [9/10], Valid Accuracy: 97.9600, Valid Loss: 0.0668\n",
      "Epoch [10/10], Loss: 0.0819\n",
      "Epoch [10/10], Valid Accuracy: 98.0100, Valid Loss: 0.0705\n",
      "Done\n",
      "Epoch [1/10], Loss: 0.3447\n",
      "Epoch [1/10], Valid Accuracy: 95.6600, Valid Loss: 0.1349\n",
      "Epoch [2/10], Loss: 0.1916\n",
      "Epoch [2/10], Valid Accuracy: 96.8800, Valid Loss: 0.1006\n",
      "Epoch [3/10], Loss: 0.1542\n",
      "Epoch [3/10], Valid Accuracy: 97.3000, Valid Loss: 0.0895\n",
      "Epoch [4/10], Loss: 0.1403\n",
      "Epoch [4/10], Valid Accuracy: 97.6500, Valid Loss: 0.0802\n",
      "Epoch [5/10], Loss: 0.1262\n",
      "Epoch [5/10], Valid Accuracy: 97.4800, Valid Loss: 0.0840\n",
      "Epoch [6/10], Loss: 0.1194\n",
      "Epoch [6/10], Valid Accuracy: 97.7900, Valid Loss: 0.0727\n",
      "Epoch [7/10], Loss: 0.1138\n",
      "Epoch [7/10], Valid Accuracy: 97.5800, Valid Loss: 0.0758\n",
      "Epoch [8/10], Loss: 0.1045\n",
      "Epoch [8/10], Valid Accuracy: 97.7500, Valid Loss: 0.0735\n",
      "Epoch [9/10], Loss: 0.1000\n",
      "Epoch [9/10], Valid Accuracy: 97.9500, Valid Loss: 0.0705\n",
      "Epoch [10/10], Loss: 0.0964\n",
      "Epoch [10/10], Valid Accuracy: 97.9300, Valid Loss: 0.0685\n",
      "Done\n",
      "Epoch [1/10], Loss: 0.3854\n",
      "Epoch [1/10], Valid Accuracy: 95.4900, Valid Loss: 0.1494\n",
      "Epoch [2/10], Loss: 0.2123\n",
      "Epoch [2/10], Valid Accuracy: 96.3500, Valid Loss: 0.1185\n",
      "Epoch [3/10], Loss: 0.1777\n",
      "Epoch [3/10], Valid Accuracy: 97.0800, Valid Loss: 0.0977\n",
      "Epoch [4/10], Loss: 0.1582\n",
      "Epoch [4/10], Valid Accuracy: 97.1800, Valid Loss: 0.0947\n",
      "Epoch [5/10], Loss: 0.1479\n",
      "Epoch [5/10], Valid Accuracy: 97.3200, Valid Loss: 0.0852\n",
      "Epoch [6/10], Loss: 0.1369\n",
      "Epoch [6/10], Valid Accuracy: 97.3700, Valid Loss: 0.0882\n",
      "Epoch [7/10], Loss: 0.1337\n",
      "Epoch [7/10], Valid Accuracy: 97.5400, Valid Loss: 0.0827\n",
      "Epoch [8/10], Loss: 0.1220\n",
      "Epoch [8/10], Valid Accuracy: 97.4700, Valid Loss: 0.0830\n",
      "Epoch [9/10], Loss: 0.1176\n",
      "Epoch [9/10], Valid Accuracy: 97.7300, Valid Loss: 0.0742\n",
      "Epoch [10/10], Loss: 0.1160\n",
      "Epoch [10/10], Valid Accuracy: 97.7300, Valid Loss: 0.0778\n",
      "Done\n",
      "Epoch [1/10], Loss: 0.4202\n",
      "Epoch [1/10], Valid Accuracy: 95.5000, Valid Loss: 0.1471\n",
      "Epoch [2/10], Loss: 0.2298\n",
      "Epoch [2/10], Valid Accuracy: 96.1900, Valid Loss: 0.1308\n",
      "Epoch [3/10], Loss: 0.1915\n",
      "Epoch [3/10], Valid Accuracy: 96.9200, Valid Loss: 0.1090\n",
      "Epoch [4/10], Loss: 0.1724\n",
      "Epoch [4/10], Valid Accuracy: 97.1400, Valid Loss: 0.0956\n",
      "Epoch [5/10], Loss: 0.1613\n",
      "Epoch [5/10], Valid Accuracy: 97.3000, Valid Loss: 0.0897\n",
      "Epoch [6/10], Loss: 0.1484\n",
      "Epoch [6/10], Valid Accuracy: 97.5500, Valid Loss: 0.0879\n",
      "Epoch [7/10], Loss: 0.1396\n",
      "Epoch [7/10], Valid Accuracy: 97.6600, Valid Loss: 0.0846\n",
      "Epoch [8/10], Loss: 0.1339\n",
      "Epoch [8/10], Valid Accuracy: 97.5800, Valid Loss: 0.0814\n",
      "Epoch [9/10], Loss: 0.1320\n",
      "Epoch [9/10], Valid Accuracy: 97.7100, Valid Loss: 0.0809\n",
      "Epoch [10/10], Loss: 0.1241\n",
      "Epoch [10/10], Valid Accuracy: 97.6700, Valid Loss: 0.0836\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "lr=0.001\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "valid_acc  = []\n",
    "for k in p:\n",
    "    net = get_model_v2(M=[300,100],p=[k['p1'],k['p2']])\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "    _,_ ,trn_loss=train_model(train_loader, test_loader, num_epochs=10, model=net, optimizer=optimizer)\n",
    "    vld_acc,val_loss=model_accuracy_loss(net, test_loader)\n",
    "    valid_loss.append(val_loss)\n",
    "    train_loss.append(trn_loss)\n",
    "    valid_acc.append(vld_acc)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = pd.DataFrame(p)\n",
    "p['valid_acc']  = valid_acc\n",
    "p['train_loss'] = train_loss\n",
    "p['valid_loss'] = valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>valid_acc</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>97.67</td>\n",
       "      <td>0.124059</td>\n",
       "      <td>0.083597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>97.69</td>\n",
       "      <td>0.065360</td>\n",
       "      <td>0.091864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>97.73</td>\n",
       "      <td>0.115971</td>\n",
       "      <td>0.077759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.76</td>\n",
       "      <td>0.019578</td>\n",
       "      <td>0.090246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>97.76</td>\n",
       "      <td>0.087824</td>\n",
       "      <td>0.073149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>97.87</td>\n",
       "      <td>0.025846</td>\n",
       "      <td>0.088577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>97.87</td>\n",
       "      <td>0.079393</td>\n",
       "      <td>0.073486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>97.88</td>\n",
       "      <td>0.045758</td>\n",
       "      <td>0.074760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>97.89</td>\n",
       "      <td>0.036380</td>\n",
       "      <td>0.095956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>97.93</td>\n",
       "      <td>0.096401</td>\n",
       "      <td>0.068521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>97.96</td>\n",
       "      <td>0.055258</td>\n",
       "      <td>0.079381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>97.97</td>\n",
       "      <td>0.098506</td>\n",
       "      <td>0.072179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>98.00</td>\n",
       "      <td>0.029318</td>\n",
       "      <td>0.081847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.01</td>\n",
       "      <td>0.081887</td>\n",
       "      <td>0.070511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.08</td>\n",
       "      <td>0.062742</td>\n",
       "      <td>0.070173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.28</td>\n",
       "      <td>0.037837</td>\n",
       "      <td>0.065586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     p1   p2  valid_acc  train_loss  valid_loss\n",
       "15  0.5  0.5      97.67    0.124059    0.083597\n",
       "7   0.2  0.5      97.69    0.065360    0.091864\n",
       "14  0.5  0.4      97.73    0.115971    0.077759\n",
       "0   0.0  0.0      97.76    0.019578    0.090246\n",
       "10  0.4  0.4      97.76    0.087824    0.073149\n",
       "1   0.0  0.2      97.87    0.025846    0.088577\n",
       "9   0.4  0.2      97.87    0.079393    0.073486\n",
       "5   0.2  0.2      97.88    0.045758    0.074760\n",
       "3   0.0  0.5      97.89    0.036380    0.095956\n",
       "13  0.5  0.2      97.93    0.096401    0.068521\n",
       "6   0.2  0.4      97.96    0.055258    0.079381\n",
       "11  0.4  0.5      97.97    0.098506    0.072179\n",
       "2   0.0  0.4      98.00    0.029318    0.081847\n",
       "12  0.5  0.0      98.01    0.081887    0.070511\n",
       "8   0.4  0.0      98.08    0.062742    0.070173\n",
       "4   0.2  0.0      98.28    0.037837    0.065586"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.sort_values(by='valid_acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have considered different dropouts  in both layers. The highest validation accuracy is achieved with drop out rate of 0.2 in layer 1 and zero drop out rate in layer 2. Compared to weight decay, dropout helps to improve testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'p1':[0.2, 0.4, 0.5],\n",
    "              'p2':[0]\n",
    "             }\n",
    "p = list(ParameterGrid(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.2473\n",
      "Epoch [1/20], Valid Accuracy: 96.4100, Valid Loss: 0.1159\n",
      "Epoch [2/20], Loss: 0.1143\n",
      "Epoch [2/20], Valid Accuracy: 96.9700, Valid Loss: 0.0983\n",
      "Epoch [3/20], Loss: 0.0877\n",
      "Epoch [3/20], Valid Accuracy: 97.6800, Valid Loss: 0.0777\n",
      "Epoch [4/20], Loss: 0.0722\n",
      "Epoch [4/20], Valid Accuracy: 97.8700, Valid Loss: 0.0676\n",
      "Epoch [5/20], Loss: 0.0600\n",
      "Epoch [5/20], Valid Accuracy: 97.8400, Valid Loss: 0.0762\n",
      "Epoch [6/20], Loss: 0.0537\n",
      "Epoch [6/20], Valid Accuracy: 97.8800, Valid Loss: 0.0751\n",
      "Epoch [7/20], Loss: 0.0484\n",
      "Epoch [7/20], Valid Accuracy: 98.1000, Valid Loss: 0.0685\n",
      "Epoch [8/20], Loss: 0.0431\n",
      "Epoch [8/20], Valid Accuracy: 98.1800, Valid Loss: 0.0676\n",
      "Epoch [9/20], Loss: 0.0406\n",
      "Epoch [9/20], Valid Accuracy: 98.0600, Valid Loss: 0.0741\n",
      "Epoch [10/20], Loss: 0.0375\n",
      "Epoch [10/20], Valid Accuracy: 98.0200, Valid Loss: 0.0730\n",
      "Epoch [11/20], Loss: 0.0341\n",
      "Epoch [11/20], Valid Accuracy: 98.0100, Valid Loss: 0.0724\n",
      "Epoch [12/20], Loss: 0.0361\n",
      "Epoch [12/20], Valid Accuracy: 97.8000, Valid Loss: 0.0774\n",
      "Epoch [13/20], Loss: 0.0297\n",
      "Epoch [13/20], Valid Accuracy: 98.2600, Valid Loss: 0.0702\n",
      "Epoch [14/20], Loss: 0.0298\n",
      "Epoch [14/20], Valid Accuracy: 98.0900, Valid Loss: 0.0758\n",
      "Epoch [15/20], Loss: 0.0319\n",
      "Epoch [15/20], Valid Accuracy: 98.0400, Valid Loss: 0.0854\n",
      "Epoch [16/20], Loss: 0.0279\n",
      "Epoch [16/20], Valid Accuracy: 98.1500, Valid Loss: 0.0777\n",
      "Epoch [17/20], Loss: 0.0245\n",
      "Epoch [17/20], Valid Accuracy: 98.2300, Valid Loss: 0.0765\n",
      "Epoch [18/20], Loss: 0.0252\n",
      "Epoch [18/20], Valid Accuracy: 98.1500, Valid Loss: 0.0783\n",
      "Epoch [19/20], Loss: 0.0237\n",
      "Epoch [19/20], Valid Accuracy: 98.4200, Valid Loss: 0.0768\n",
      "Epoch [20/20], Loss: 0.0242\n",
      "Epoch [20/20], Valid Accuracy: 98.3400, Valid Loss: 0.0815\n",
      "Done\n",
      "Epoch [1/20], Loss: 0.2894\n",
      "Epoch [1/20], Valid Accuracy: 95.9700, Valid Loss: 0.1287\n",
      "Epoch [2/20], Loss: 0.1484\n",
      "Epoch [2/20], Valid Accuracy: 96.9700, Valid Loss: 0.0929\n",
      "Epoch [3/20], Loss: 0.1183\n",
      "Epoch [3/20], Valid Accuracy: 97.3200, Valid Loss: 0.0851\n",
      "Epoch [4/20], Loss: 0.1026\n",
      "Epoch [4/20], Valid Accuracy: 97.3400, Valid Loss: 0.0826\n",
      "Epoch [5/20], Loss: 0.0918\n",
      "Epoch [5/20], Valid Accuracy: 97.6700, Valid Loss: 0.0737\n",
      "Epoch [6/20], Loss: 0.0831\n",
      "Epoch [6/20], Valid Accuracy: 97.9200, Valid Loss: 0.0723\n",
      "Epoch [7/20], Loss: 0.0781\n",
      "Epoch [7/20], Valid Accuracy: 97.9200, Valid Loss: 0.0661\n",
      "Epoch [8/20], Loss: 0.0715\n",
      "Epoch [8/20], Valid Accuracy: 98.1200, Valid Loss: 0.0615\n",
      "Epoch [9/20], Loss: 0.0708\n",
      "Epoch [9/20], Valid Accuracy: 98.1900, Valid Loss: 0.0586\n",
      "Epoch [10/20], Loss: 0.0627\n",
      "Epoch [10/20], Valid Accuracy: 98.1300, Valid Loss: 0.0619\n",
      "Epoch [11/20], Loss: 0.0619\n",
      "Epoch [11/20], Valid Accuracy: 98.1800, Valid Loss: 0.0607\n",
      "Epoch [12/20], Loss: 0.0565\n",
      "Epoch [12/20], Valid Accuracy: 98.0200, Valid Loss: 0.0692\n",
      "Epoch [13/20], Loss: 0.0573\n",
      "Epoch [13/20], Valid Accuracy: 98.1000, Valid Loss: 0.0700\n",
      "Epoch [14/20], Loss: 0.0559\n",
      "Epoch [14/20], Valid Accuracy: 98.1700, Valid Loss: 0.0711\n",
      "Epoch [15/20], Loss: 0.0519\n",
      "Epoch [15/20], Valid Accuracy: 98.0700, Valid Loss: 0.0669\n",
      "Epoch [16/20], Loss: 0.0493\n",
      "Epoch [16/20], Valid Accuracy: 98.2600, Valid Loss: 0.0658\n",
      "Epoch [17/20], Loss: 0.0484\n",
      "Epoch [17/20], Valid Accuracy: 98.1400, Valid Loss: 0.0706\n",
      "Epoch [18/20], Loss: 0.0476\n",
      "Epoch [18/20], Valid Accuracy: 98.2800, Valid Loss: 0.0665\n",
      "Epoch [19/20], Loss: 0.0464\n",
      "Epoch [19/20], Valid Accuracy: 98.0300, Valid Loss: 0.0700\n",
      "Epoch [20/20], Loss: 0.0455\n",
      "Epoch [20/20], Valid Accuracy: 98.0100, Valid Loss: 0.0680\n",
      "Done\n",
      "Epoch [1/20], Loss: 0.3201\n",
      "Epoch [1/20], Valid Accuracy: 96.0100, Valid Loss: 0.1320\n",
      "Epoch [2/20], Loss: 0.1735\n",
      "Epoch [2/20], Valid Accuracy: 96.9100, Valid Loss: 0.1033\n",
      "Epoch [3/20], Loss: 0.1446\n",
      "Epoch [3/20], Valid Accuracy: 97.1800, Valid Loss: 0.0921\n",
      "Epoch [4/20], Loss: 0.1262\n",
      "Epoch [4/20], Valid Accuracy: 97.4300, Valid Loss: 0.0865\n",
      "Epoch [5/20], Loss: 0.1144\n",
      "Epoch [5/20], Valid Accuracy: 97.4400, Valid Loss: 0.0851\n",
      "Epoch [6/20], Loss: 0.1057\n",
      "Epoch [6/20], Valid Accuracy: 97.7500, Valid Loss: 0.0749\n",
      "Epoch [7/20], Loss: 0.0979\n",
      "Epoch [7/20], Valid Accuracy: 97.9000, Valid Loss: 0.0732\n",
      "Epoch [8/20], Loss: 0.0929\n",
      "Epoch [8/20], Valid Accuracy: 97.8600, Valid Loss: 0.0714\n",
      "Epoch [9/20], Loss: 0.0893\n",
      "Epoch [9/20], Valid Accuracy: 97.8800, Valid Loss: 0.0728\n",
      "Epoch [10/20], Loss: 0.0835\n",
      "Epoch [10/20], Valid Accuracy: 97.6900, Valid Loss: 0.0768\n",
      "Epoch [11/20], Loss: 0.0814\n",
      "Epoch [11/20], Valid Accuracy: 98.0200, Valid Loss: 0.0681\n",
      "Epoch [12/20], Loss: 0.0785\n",
      "Epoch [12/20], Valid Accuracy: 98.0500, Valid Loss: 0.0668\n",
      "Epoch [13/20], Loss: 0.0753\n",
      "Epoch [13/20], Valid Accuracy: 98.2900, Valid Loss: 0.0599\n",
      "Epoch [14/20], Loss: 0.0734\n",
      "Epoch [14/20], Valid Accuracy: 98.0400, Valid Loss: 0.0642\n",
      "Epoch [15/20], Loss: 0.0688\n",
      "Epoch [15/20], Valid Accuracy: 98.2000, Valid Loss: 0.0632\n",
      "Epoch [16/20], Loss: 0.0687\n",
      "Epoch [16/20], Valid Accuracy: 98.0400, Valid Loss: 0.0686\n",
      "Epoch [17/20], Loss: 0.0659\n",
      "Epoch [17/20], Valid Accuracy: 98.3200, Valid Loss: 0.0617\n",
      "Epoch [18/20], Loss: 0.0674\n",
      "Epoch [18/20], Valid Accuracy: 97.9900, Valid Loss: 0.0750\n",
      "Epoch [19/20], Loss: 0.0655\n",
      "Epoch [19/20], Valid Accuracy: 98.1500, Valid Loss: 0.0629\n",
      "Epoch [20/20], Loss: 0.0627\n",
      "Epoch [20/20], Valid Accuracy: 98.1400, Valid Loss: 0.0670\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>valid_acc</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>98.01</td>\n",
       "      <td>0.045517</td>\n",
       "      <td>0.067978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>98.14</td>\n",
       "      <td>0.062695</td>\n",
       "      <td>0.067033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>98.34</td>\n",
       "      <td>0.024237</td>\n",
       "      <td>0.081472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    p1  p2  valid_acc  train_loss  valid_loss\n",
       "1  0.4   0      98.01    0.045517    0.067978\n",
       "2  0.5   0      98.14    0.062695    0.067033\n",
       "0  0.2   0      98.34    0.024237    0.081472"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr=0.001\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "valid_acc  = []\n",
    "for k in p:\n",
    "    net = get_model_v2(M=[300,100],p=[k['p1'],k['p2']])\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "    _,_ ,trn_loss=train_model(train_loader, test_loader, num_epochs=20, model=net, optimizer=optimizer)\n",
    "    vld_acc,val_loss=model_accuracy_loss(net, test_loader)\n",
    "    valid_loss.append(val_loss)\n",
    "    train_loss.append(trn_loss)\n",
    "    valid_acc.append(vld_acc)\n",
    "    print('Done')\n",
    "p = pd.DataFrame(p)\n",
    "p['valid_acc']  = valid_acc\n",
    "p['train_loss'] = train_loss\n",
    "p['valid_loss'] = valid_loss\n",
    "p.sort_values(by='valid_acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Weight decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.2450\n",
      "Epoch [1/20], Valid Accuracy: 96.4200, Valid Loss: 0.1164\n",
      "Epoch [2/20], Loss: 0.1133\n",
      "Epoch [2/20], Valid Accuracy: 97.0100, Valid Loss: 0.1016\n",
      "Epoch [3/20], Loss: 0.0864\n",
      "Epoch [3/20], Valid Accuracy: 97.6900, Valid Loss: 0.0731\n",
      "Epoch [4/20], Loss: 0.0710\n",
      "Epoch [4/20], Valid Accuracy: 97.7800, Valid Loss: 0.0724\n",
      "Epoch [5/20], Loss: 0.0612\n",
      "Epoch [5/20], Valid Accuracy: 98.0100, Valid Loss: 0.0690\n",
      "Epoch [6/20], Loss: 0.0520\n",
      "Epoch [6/20], Valid Accuracy: 97.9700, Valid Loss: 0.0676\n",
      "Epoch [7/20], Loss: 0.0461\n",
      "Epoch [7/20], Valid Accuracy: 97.5500, Valid Loss: 0.0910\n",
      "Epoch [8/20], Loss: 0.0442\n",
      "Epoch [8/20], Valid Accuracy: 98.0200, Valid Loss: 0.0748\n",
      "Epoch [9/20], Loss: 0.0394\n",
      "Epoch [9/20], Valid Accuracy: 97.5100, Valid Loss: 0.0919\n",
      "Epoch [10/20], Loss: 0.0371\n",
      "Epoch [10/20], Valid Accuracy: 98.1400, Valid Loss: 0.0720\n",
      "Epoch [11/20], Loss: 0.0356\n",
      "Epoch [11/20], Valid Accuracy: 98.1300, Valid Loss: 0.0782\n",
      "Epoch [12/20], Loss: 0.0336\n",
      "Epoch [12/20], Valid Accuracy: 97.9800, Valid Loss: 0.0744\n",
      "Epoch [13/20], Loss: 0.0354\n",
      "Epoch [13/20], Valid Accuracy: 98.4100, Valid Loss: 0.0658\n",
      "Epoch [14/20], Loss: 0.0285\n",
      "Epoch [14/20], Valid Accuracy: 98.1700, Valid Loss: 0.0815\n",
      "Epoch [15/20], Loss: 0.0308\n",
      "Epoch [15/20], Valid Accuracy: 98.2100, Valid Loss: 0.0776\n",
      "Epoch [16/20], Loss: 0.0262\n",
      "Epoch [16/20], Valid Accuracy: 98.2500, Valid Loss: 0.0769\n",
      "Epoch [17/20], Loss: 0.0279\n",
      "Epoch [17/20], Valid Accuracy: 98.0900, Valid Loss: 0.0839\n",
      "Epoch [18/20], Loss: 0.0265\n",
      "Epoch [18/20], Valid Accuracy: 98.2500, Valid Loss: 0.0808\n",
      "Epoch [19/20], Loss: 0.0260\n",
      "Epoch [19/20], Valid Accuracy: 97.9100, Valid Loss: 0.0909\n",
      "Epoch [20/20], Loss: 0.0235\n",
      "Epoch [20/20], Valid Accuracy: 98.1400, Valid Loss: 0.0884\n",
      "Done\n",
      "Epoch [1/20], Loss: 0.2469\n",
      "Epoch [1/20], Valid Accuracy: 96.5800, Valid Loss: 0.1094\n",
      "Epoch [2/20], Loss: 0.1155\n",
      "Epoch [2/20], Valid Accuracy: 97.1700, Valid Loss: 0.0926\n",
      "Epoch [3/20], Loss: 0.0902\n",
      "Epoch [3/20], Valid Accuracy: 97.2200, Valid Loss: 0.0875\n",
      "Epoch [4/20], Loss: 0.0750\n",
      "Epoch [4/20], Valid Accuracy: 97.7000, Valid Loss: 0.0807\n",
      "Epoch [5/20], Loss: 0.0651\n",
      "Epoch [5/20], Valid Accuracy: 97.6600, Valid Loss: 0.0774\n",
      "Epoch [6/20], Loss: 0.0594\n",
      "Epoch [6/20], Valid Accuracy: 98.0200, Valid Loss: 0.0655\n",
      "Epoch [7/20], Loss: 0.0565\n",
      "Epoch [7/20], Valid Accuracy: 97.7100, Valid Loss: 0.0836\n",
      "Epoch [8/20], Loss: 0.0511\n",
      "Epoch [8/20], Valid Accuracy: 98.2000, Valid Loss: 0.0630\n",
      "Epoch [9/20], Loss: 0.0498\n",
      "Epoch [9/20], Valid Accuracy: 97.9300, Valid Loss: 0.0714\n",
      "Epoch [10/20], Loss: 0.0455\n",
      "Epoch [10/20], Valid Accuracy: 97.9700, Valid Loss: 0.0672\n",
      "Epoch [11/20], Loss: 0.0448\n",
      "Epoch [11/20], Valid Accuracy: 98.1100, Valid Loss: 0.0692\n",
      "Epoch [12/20], Loss: 0.0455\n",
      "Epoch [12/20], Valid Accuracy: 98.1500, Valid Loss: 0.0628\n",
      "Epoch [13/20], Loss: 0.0412\n",
      "Epoch [13/20], Valid Accuracy: 97.0500, Valid Loss: 0.1129\n",
      "Epoch [14/20], Loss: 0.0423\n",
      "Epoch [14/20], Valid Accuracy: 98.0600, Valid Loss: 0.0675\n",
      "Epoch [15/20], Loss: 0.0421\n",
      "Epoch [15/20], Valid Accuracy: 98.0900, Valid Loss: 0.0680\n",
      "Epoch [16/20], Loss: 0.0375\n",
      "Epoch [16/20], Valid Accuracy: 98.2200, Valid Loss: 0.0628\n",
      "Epoch [17/20], Loss: 0.0379\n",
      "Epoch [17/20], Valid Accuracy: 97.9400, Valid Loss: 0.0691\n",
      "Epoch [18/20], Loss: 0.0352\n",
      "Epoch [18/20], Valid Accuracy: 97.9900, Valid Loss: 0.0739\n",
      "Epoch [19/20], Loss: 0.0366\n",
      "Epoch [19/20], Valid Accuracy: 98.1600, Valid Loss: 0.0666\n",
      "Epoch [20/20], Loss: 0.0377\n",
      "Epoch [20/20], Valid Accuracy: 98.1900, Valid Loss: 0.0662\n",
      "Done\n",
      "Epoch [1/20], Loss: 0.2538\n",
      "Epoch [1/20], Valid Accuracy: 96.3800, Valid Loss: 0.1155\n",
      "Epoch [2/20], Loss: 0.1314\n",
      "Epoch [2/20], Valid Accuracy: 96.1600, Valid Loss: 0.1248\n",
      "Epoch [3/20], Loss: 0.1126\n",
      "Epoch [3/20], Valid Accuracy: 96.9200, Valid Loss: 0.0943\n",
      "Epoch [4/20], Loss: 0.1029\n",
      "Epoch [4/20], Valid Accuracy: 97.3000, Valid Loss: 0.0873\n",
      "Epoch [5/20], Loss: 0.1007\n",
      "Epoch [5/20], Valid Accuracy: 97.3100, Valid Loss: 0.0857\n",
      "Epoch [6/20], Loss: 0.0954\n",
      "Epoch [6/20], Valid Accuracy: 97.4300, Valid Loss: 0.0848\n",
      "Epoch [7/20], Loss: 0.0922\n",
      "Epoch [7/20], Valid Accuracy: 97.5800, Valid Loss: 0.0782\n",
      "Epoch [8/20], Loss: 0.0911\n",
      "Epoch [8/20], Valid Accuracy: 97.6900, Valid Loss: 0.0727\n",
      "Epoch [9/20], Loss: 0.0903\n",
      "Epoch [9/20], Valid Accuracy: 97.6400, Valid Loss: 0.0804\n",
      "Epoch [10/20], Loss: 0.0882\n",
      "Epoch [10/20], Valid Accuracy: 97.4500, Valid Loss: 0.0812\n",
      "Epoch [11/20], Loss: 0.0862\n",
      "Epoch [11/20], Valid Accuracy: 97.4000, Valid Loss: 0.0854\n",
      "Epoch [12/20], Loss: 0.0852\n",
      "Epoch [12/20], Valid Accuracy: 97.4300, Valid Loss: 0.0802\n",
      "Epoch [13/20], Loss: 0.0841\n",
      "Epoch [13/20], Valid Accuracy: 97.3300, Valid Loss: 0.0817\n",
      "Epoch [14/20], Loss: 0.0845\n",
      "Epoch [14/20], Valid Accuracy: 97.6300, Valid Loss: 0.0719\n",
      "Epoch [15/20], Loss: 0.0844\n",
      "Epoch [15/20], Valid Accuracy: 97.2000, Valid Loss: 0.0880\n",
      "Epoch [16/20], Loss: 0.0834\n",
      "Epoch [16/20], Valid Accuracy: 97.6600, Valid Loss: 0.0734\n",
      "Epoch [17/20], Loss: 0.0816\n",
      "Epoch [17/20], Valid Accuracy: 97.3900, Valid Loss: 0.0861\n",
      "Epoch [18/20], Loss: 0.0841\n",
      "Epoch [18/20], Valid Accuracy: 97.5000, Valid Loss: 0.0797\n",
      "Epoch [19/20], Loss: 0.0811\n",
      "Epoch [19/20], Valid Accuracy: 97.7900, Valid Loss: 0.0705\n",
      "Epoch [20/20], Loss: 0.0819\n",
      "Epoch [20/20], Valid Accuracy: 97.7200, Valid Loss: 0.0770\n",
      "Done\n",
      "Epoch [1/20], Loss: 0.3154\n",
      "Epoch [1/20], Valid Accuracy: 94.7300, Valid Loss: 0.1947\n",
      "Epoch [2/20], Loss: 0.2218\n",
      "Epoch [2/20], Valid Accuracy: 95.5900, Valid Loss: 0.1518\n",
      "Epoch [3/20], Loss: 0.2090\n",
      "Epoch [3/20], Valid Accuracy: 94.9000, Valid Loss: 0.1733\n",
      "Epoch [4/20], Loss: 0.2039\n",
      "Epoch [4/20], Valid Accuracy: 94.6900, Valid Loss: 0.1835\n",
      "Epoch [5/20], Loss: 0.2018\n",
      "Epoch [5/20], Valid Accuracy: 95.3700, Valid Loss: 0.1702\n",
      "Epoch [6/20], Loss: 0.1983\n",
      "Epoch [6/20], Valid Accuracy: 94.8400, Valid Loss: 0.1767\n",
      "Epoch [7/20], Loss: 0.1978\n",
      "Epoch [7/20], Valid Accuracy: 95.0400, Valid Loss: 0.1743\n",
      "Epoch [8/20], Loss: 0.1959\n",
      "Epoch [8/20], Valid Accuracy: 95.9800, Valid Loss: 0.1438\n",
      "Epoch [9/20], Loss: 0.1970\n",
      "Epoch [9/20], Valid Accuracy: 95.4800, Valid Loss: 0.1582\n",
      "Epoch [10/20], Loss: 0.1936\n",
      "Epoch [10/20], Valid Accuracy: 95.2700, Valid Loss: 0.1587\n",
      "Epoch [11/20], Loss: 0.1940\n",
      "Epoch [11/20], Valid Accuracy: 95.2100, Valid Loss: 0.1607\n",
      "Epoch [12/20], Loss: 0.1907\n",
      "Epoch [12/20], Valid Accuracy: 95.7500, Valid Loss: 0.1520\n",
      "Epoch [13/20], Loss: 0.1921\n",
      "Epoch [13/20], Valid Accuracy: 95.7300, Valid Loss: 0.1484\n",
      "Epoch [14/20], Loss: 0.1916\n",
      "Epoch [14/20], Valid Accuracy: 95.3700, Valid Loss: 0.1600\n",
      "Epoch [15/20], Loss: 0.1931\n",
      "Epoch [15/20], Valid Accuracy: 96.0700, Valid Loss: 0.1496\n",
      "Epoch [16/20], Loss: 0.1939\n",
      "Epoch [16/20], Valid Accuracy: 95.5100, Valid Loss: 0.1589\n",
      "Epoch [17/20], Loss: 0.1928\n",
      "Epoch [17/20], Valid Accuracy: 94.9700, Valid Loss: 0.1732\n",
      "Epoch [18/20], Loss: 0.1937\n",
      "Epoch [18/20], Valid Accuracy: 95.3100, Valid Loss: 0.1623\n",
      "Epoch [19/20], Loss: 0.1920\n",
      "Epoch [19/20], Valid Accuracy: 95.9400, Valid Loss: 0.1482\n",
      "Epoch [20/20], Loss: 0.1901\n",
      "Epoch [20/20], Valid Accuracy: 95.9400, Valid Loss: 0.1474\n",
      "Done\n",
      "Epoch [1/20], Loss: 0.6691\n",
      "Epoch [1/20], Valid Accuracy: 85.5200, Valid Loss: 0.5760\n",
      "Epoch [2/20], Loss: 0.6174\n",
      "Epoch [2/20], Valid Accuracy: 83.8100, Valid Loss: 0.5885\n",
      "Epoch [3/20], Loss: 0.6110\n",
      "Epoch [3/20], Valid Accuracy: 87.1900, Valid Loss: 0.5498\n",
      "Epoch [4/20], Loss: 0.6052\n",
      "Epoch [4/20], Valid Accuracy: 85.5100, Valid Loss: 0.5794\n",
      "Epoch [5/20], Loss: 0.6040\n",
      "Epoch [5/20], Valid Accuracy: 87.1900, Valid Loss: 0.5486\n",
      "Epoch [6/20], Loss: 0.6061\n",
      "Epoch [6/20], Valid Accuracy: 85.3900, Valid Loss: 0.5733\n",
      "Epoch [7/20], Loss: 0.6041\n",
      "Epoch [7/20], Valid Accuracy: 84.7200, Valid Loss: 0.5970\n",
      "Epoch [8/20], Loss: 0.6014\n",
      "Epoch [8/20], Valid Accuracy: 84.9800, Valid Loss: 0.5923\n",
      "Epoch [9/20], Loss: 0.6020\n",
      "Epoch [9/20], Valid Accuracy: 87.1500, Valid Loss: 0.5461\n",
      "Epoch [10/20], Loss: 0.5998\n",
      "Epoch [10/20], Valid Accuracy: 86.7200, Valid Loss: 0.5562\n",
      "Epoch [11/20], Loss: 0.6034\n",
      "Epoch [11/20], Valid Accuracy: 86.4700, Valid Loss: 0.5588\n",
      "Epoch [12/20], Loss: 0.5998\n",
      "Epoch [12/20], Valid Accuracy: 85.8800, Valid Loss: 0.5606\n",
      "Epoch [13/20], Loss: 0.5993\n",
      "Epoch [13/20], Valid Accuracy: 86.7800, Valid Loss: 0.5524\n",
      "Epoch [14/20], Loss: 0.5998\n",
      "Epoch [14/20], Valid Accuracy: 85.8200, Valid Loss: 0.5614\n",
      "Epoch [15/20], Loss: 0.6000\n",
      "Epoch [15/20], Valid Accuracy: 86.6000, Valid Loss: 0.5528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Loss: 0.5998\n",
      "Epoch [16/20], Valid Accuracy: 85.5700, Valid Loss: 0.5729\n",
      "Epoch [17/20], Loss: 0.5991\n",
      "Epoch [17/20], Valid Accuracy: 85.5400, Valid Loss: 0.5750\n",
      "Epoch [18/20], Loss: 0.5988\n",
      "Epoch [18/20], Valid Accuracy: 85.4900, Valid Loss: 0.5723\n",
      "Epoch [19/20], Loss: 0.5993\n",
      "Epoch [19/20], Valid Accuracy: 86.9800, Valid Loss: 0.5541\n",
      "Epoch [20/20], Loss: 0.6006\n",
      "Epoch [20/20], Valid Accuracy: 84.5300, Valid Loss: 0.5947\n",
      "Done\n",
      "Epoch [1/20], Loss: 1.3485\n",
      "Epoch [1/20], Valid Accuracy: 66.1700, Valid Loss: 1.2753\n",
      "Epoch [2/20], Loss: 1.2899\n",
      "Epoch [2/20], Valid Accuracy: 65.1300, Valid Loss: 1.2451\n",
      "Epoch [3/20], Loss: 1.2861\n",
      "Epoch [3/20], Valid Accuracy: 64.4100, Valid Loss: 1.2501\n",
      "Epoch [4/20], Loss: 1.2866\n",
      "Epoch [4/20], Valid Accuracy: 66.9700, Valid Loss: 1.2594\n",
      "Epoch [5/20], Loss: 1.2837\n",
      "Epoch [5/20], Valid Accuracy: 67.1400, Valid Loss: 1.2529\n",
      "Epoch [6/20], Loss: 1.2795\n",
      "Epoch [6/20], Valid Accuracy: 63.2900, Valid Loss: 1.2641\n",
      "Epoch [7/20], Loss: 1.2814\n",
      "Epoch [7/20], Valid Accuracy: 66.7600, Valid Loss: 1.3070\n",
      "Epoch [8/20], Loss: 1.2827\n",
      "Epoch [8/20], Valid Accuracy: 68.2000, Valid Loss: 1.2451\n",
      "Epoch [9/20], Loss: 1.2791\n",
      "Epoch [9/20], Valid Accuracy: 65.0700, Valid Loss: 1.2489\n",
      "Epoch [10/20], Loss: 1.2823\n",
      "Epoch [10/20], Valid Accuracy: 64.8600, Valid Loss: 1.2728\n",
      "Epoch [11/20], Loss: 1.2781\n",
      "Epoch [11/20], Valid Accuracy: 64.0400, Valid Loss: 1.2775\n",
      "Epoch [12/20], Loss: 1.2795\n",
      "Epoch [12/20], Valid Accuracy: 64.9500, Valid Loss: 1.2551\n",
      "Epoch [13/20], Loss: 1.2788\n",
      "Epoch [13/20], Valid Accuracy: 63.9500, Valid Loss: 1.2528\n",
      "Epoch [14/20], Loss: 1.2803\n",
      "Epoch [14/20], Valid Accuracy: 66.7900, Valid Loss: 1.2423\n",
      "Epoch [15/20], Loss: 1.2772\n",
      "Epoch [15/20], Valid Accuracy: 69.4500, Valid Loss: 1.2279\n",
      "Epoch [16/20], Loss: 1.2774\n",
      "Epoch [16/20], Valid Accuracy: 66.4400, Valid Loss: 1.2488\n",
      "Epoch [17/20], Loss: 1.2760\n",
      "Epoch [17/20], Valid Accuracy: 67.1100, Valid Loss: 1.2561\n",
      "Epoch [18/20], Loss: 1.2775\n",
      "Epoch [18/20], Valid Accuracy: 66.4400, Valid Loss: 1.2661\n",
      "Epoch [19/20], Loss: 1.2752\n",
      "Epoch [19/20], Valid Accuracy: 67.1800, Valid Loss: 1.2557\n",
      "Epoch [20/20], Loss: 1.2776\n",
      "Epoch [20/20], Valid Accuracy: 67.8300, Valid Loss: 1.2434\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "wd = [0, 0.0001, 0.001, 0.01, 0.1, 0.3]\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "valid_acc  = []\n",
    "lr=0.001\n",
    "for w in wd:\n",
    "    net = get_model_v2(M=[300,150],p=[0.2,0])\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr,weight_decay=w)\n",
    "    _,_ ,trn_loss=train_model(train_loader, test_loader, num_epochs=20, model=net, optimizer=optimizer)\n",
    "    vld_acc,val_loss=model_accuracy_loss(net, test_loader)\n",
    "    valid_loss.append(val_loss)\n",
    "    train_loss.append(trn_loss)\n",
    "    valid_acc.append(vld_acc)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wt decay</th>\n",
       "      <th>vld_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.3000</td>\n",
       "      <td>67.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>84.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>95.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>97.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>98.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>98.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    wt decay  vld_acc\n",
       "5     0.3000    67.83\n",
       "4     0.1000    84.53\n",
       "3     0.0100    95.94\n",
       "2     0.0010    97.72\n",
       "0     0.0000    98.14\n",
       "1     0.0001    98.19"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({' wt decay':wd,\n",
    "             'vld_acc': valid_acc}).sort_values(by='vld_acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The 3 layer network too worked well without weight decay. When 3 layer network was compared to 2 layer network, there was no improvement in the validation accuracy compared to the 2 layer network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
